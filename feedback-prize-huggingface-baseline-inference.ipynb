{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# HuggingFace Inference Baseline\n",
    "\n",
    "Training notebook: https://www.kaggle.com/thedrcat/feedback-prize-huggingface-baseline-training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Config\n",
    "batch_size = 1\n",
    "min_tokens = 5\n",
    "tok_checkpoint = 'longformer-base-4096-hf-1/'\n",
    "model_checkpoint = 'longformer-base-4096-hf-1/pytorch_model.bin'"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-24T06:10:33.53461Z",
     "iopub.execute_input": "2021-12-24T06:10:33.534874Z",
     "iopub.status.idle": "2021-12-24T06:10:33.540694Z",
     "shell.execute_reply.started": "2021-12-24T06:10:33.534844Z",
     "shell.execute_reply": "2021-12-24T06:10:33.538986Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load data\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('data/train.csv')\n",
    "train.head(1)\n",
    "\n",
    "test = pd.read_csv('data/sample_submission.csv')\n",
    "test.head(1)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-24T06:10:34.007753Z",
     "iopub.execute_input": "2021-12-24T06:10:34.00816Z",
     "iopub.status.idle": "2021-12-24T06:10:35.81608Z",
     "shell.execute_reply.started": "2021-12-24T06:10:34.008122Z",
     "shell.execute_reply": "2021-12-24T06:10:35.815223Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "             id  class  predictionstring\n0  18409261F5C2    NaN               NaN",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>class</th>\n      <th>predictionstring</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>18409261F5C2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Setup dictionaries\n",
    "classes = train.discourse_type.unique().tolist()\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "tags = defaultdict()\n",
    "for i, c in enumerate(classes):\n",
    "    tags[f'B-{c}'] = i\n",
    "    tags[f'I-{c}'] = i + len(classes)\n",
    "tags[f'O'] = len(classes) * 2\n",
    "tags[f'Special'] = -100\n",
    "l2i = dict(tags)\n",
    "\n",
    "i2l = defaultdict()\n",
    "for k, v in l2i.items(): \n",
    "    i2l[v] = k\n",
    "i2l[-100] = 'Special'\n",
    "i2l = dict(i2l)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-24T06:10:35.817956Z",
     "iopub.execute_input": "2021-12-24T06:10:35.818285Z",
     "iopub.status.idle": "2021-12-24T06:10:35.845445Z",
     "shell.execute_reply.started": "2021-12-24T06:10:35.818248Z",
     "shell.execute_reply": "2021-12-24T06:10:35.844633Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Helper functions\n",
    "from pathlib import Path\n",
    "\n",
    "test_path = Path('data/test')\n",
    "\n",
    "def get_test_text(ids):\n",
    "    with open(test_path/f'{ids}.txt', 'r') as file: data = file.read()\n",
    "    return data"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-24T06:10:35.847276Z",
     "iopub.execute_input": "2021-12-24T06:10:35.847583Z",
     "iopub.status.idle": "2021-12-24T06:10:35.853177Z",
     "shell.execute_reply.started": "2021-12-24T06:10:35.847547Z",
     "shell.execute_reply": "2021-12-24T06:10:35.852277Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(tok_checkpoint, add_prefix_space=True)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-24T06:10:38.408127Z",
     "iopub.execute_input": "2021-12-24T06:10:38.408862Z",
     "iopub.status.idle": "2021-12-24T06:10:45.190207Z",
     "shell.execute_reply.started": "2021-12-24T06:10:38.408823Z",
     "shell.execute_reply": "2021-12-24T06:10:45.189449Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load model\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "import torch\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(tok_checkpoint, num_labels=len(i2l)-1)\n",
    "\n",
    "model.load_state_dict(torch.load(model_checkpoint))\n",
    "model.eval();"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-24T06:10:45.19514Z",
     "iopub.execute_input": "2021-12-24T06:10:45.196841Z",
     "iopub.status.idle": "2021-12-24T06:11:06.430638Z",
     "shell.execute_reply.started": "2021-12-24T06:10:45.196795Z",
     "shell.execute_reply": "2021-12-24T06:11:06.429865Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-24T06:11:06.431861Z",
     "iopub.execute_input": "2021-12-24T06:11:06.43376Z",
     "iopub.status.idle": "2021-12-24T06:11:06.439251Z",
     "shell.execute_reply.started": "2021-12-24T06:11:06.433718Z",
     "shell.execute_reply": "2021-12-24T06:11:06.437151Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# We'll use trainer with the loaded model to run inference on test set\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-24T06:11:06.441463Z",
     "iopub.execute_input": "2021-12-24T06:11:06.442026Z",
     "iopub.status.idle": "2021-12-24T06:11:07.396345Z",
     "shell.execute_reply.started": "2021-12-24T06:11:06.441988Z",
     "shell.execute_reply": "2021-12-24T06:11:07.395494Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# code that will convert our predictions into prediction strings. we'll skip visualization here. \n",
    "# this most likely requires some refactoring\n",
    "\n",
    "def get_class(c):\n",
    "    if c == 14: return 'Other'\n",
    "    else: return i2l[c][2:]\n",
    "\n",
    "def pred2span(pred, example, viz=False, test=False):\n",
    "    example_id = example['id']\n",
    "    n_tokens = len(example['input_ids'])\n",
    "    classes = []\n",
    "    all_span = []\n",
    "    for i, c in enumerate(pred.tolist()):\n",
    "        if i == n_tokens-1:\n",
    "            break\n",
    "        if i == 0:\n",
    "            cur_span = example['offset_mapping'][i]\n",
    "            classes.append(get_class(c))\n",
    "        elif i > 0 and (c == pred[i-1] or (c-7) == pred[i-1]):\n",
    "            cur_span[1] = example['offset_mapping'][i][1]\n",
    "        else:\n",
    "            all_span.append(cur_span)\n",
    "            cur_span = example['offset_mapping'][i]\n",
    "            classes.append(get_class(c))\n",
    "    all_span.append(cur_span)\n",
    "    \n",
    "    if test: text = get_test_text(example_id)\n",
    "    else: text = get_raw_text(example_id)\n",
    "        \n",
    "    # map token ids to word (whitespace) token ids\n",
    "    predstrings = []\n",
    "    for span in all_span:\n",
    "        span_start = span[0]\n",
    "        span_end = span[1]\n",
    "        before = text[:span_start]\n",
    "        token_start = len(before.split())\n",
    "        if len(before) == 0: token_start = 0\n",
    "        elif before[-1] != ' ': token_start -= 1\n",
    "        num_tkns = len(text[span_start:span_end+1].split())\n",
    "        tkns = [str(x) for x in range(token_start, token_start+num_tkns)]\n",
    "        predstring = ' '.join(tkns)\n",
    "        predstrings.append(predstring)\n",
    "                    \n",
    "    rows = []\n",
    "    for c, span, predstring in zip(classes, all_span, predstrings):\n",
    "        e = {\n",
    "            'id': example_id,\n",
    "            'discourse_type': c,\n",
    "            'predictionstring': predstring,\n",
    "            'discourse_start': span[0],\n",
    "            'discourse_end': span[1],\n",
    "            'discourse': text[span[0]:span[1]+1]\n",
    "        }\n",
    "        rows.append(e)\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df['length'] = df['discourse'].apply(lambda t: len(t.split()))\n",
    "    \n",
    "    # short spans are likely to be false positives, we can choose a min number of tokens based on validation\n",
    "    df = df[df.length > min_tokens].reset_index(drop=True)\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-24T06:11:07.400847Z",
     "iopub.execute_input": "2021-12-24T06:11:07.401127Z",
     "iopub.status.idle": "2021-12-24T06:11:07.41777Z",
     "shell.execute_reply.started": "2021-12-24T06:11:07.401098Z",
     "shell.execute_reply": "2021-12-24T06:11:07.417021Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load test data\n",
    "import os \n",
    "\n",
    "files = os.listdir('data/test')\n",
    "ids = [x.split('.')[0] for x in files]\n",
    "\n",
    "df_test = pd.DataFrame()\n",
    "df_test['id'] = ids\n",
    "df_test['text'] = df_test['id'].apply(get_test_text)\n",
    "df_test"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-24T06:11:07.419548Z",
     "iopub.execute_input": "2021-12-24T06:11:07.420148Z",
     "iopub.status.idle": "2021-12-24T06:11:07.454812Z",
     "shell.execute_reply.started": "2021-12-24T06:11:07.42011Z",
     "shell.execute_reply": "2021-12-24T06:11:07.454201Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "             id                                               text\n0  DF920E0A7337  Have you ever asked more than one person for h...\n1  18409261F5C2  80% of Americans believe seeking multiple opin...\n2  D72CB1C11673  Making choices in life can be very difficult. ...\n3  0FB0700DAF44  During a group project, have you ever asked a ...\n4  D46BCB48440A  When people ask for advice,they sometimes talk...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>DF920E0A7337</td>\n      <td>Have you ever asked more than one person for h...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>18409261F5C2</td>\n      <td>80% of Americans believe seeking multiple opin...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>D72CB1C11673</td>\n      <td>Making choices in life can be very difficult. ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0FB0700DAF44</td>\n      <td>During a group project, have you ever asked a ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>D46BCB48440A</td>\n      <td>When people ask for advice,they sometimes talk...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "from datasets import Dataset\n\ntest_ds = Dataset.from_pandas(df_test)\ntest_ds",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-24T06:11:07.456311Z",
     "iopub.execute_input": "2021-12-24T06:11:07.456689Z",
     "iopub.status.idle": "2021-12-24T06:11:07.47858Z",
     "shell.execute_reply.started": "2021-12-24T06:11:07.456656Z",
     "shell.execute_reply": "2021-12-24T06:11:07.477801Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['id', 'text'],\n    num_rows: 5\n})"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "def tokenize_for_test(examples):\n\n    o = tokenizer(examples['text'], truncation=True, return_offsets_mapping=True, max_length=4096)\n  \n    return o",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-24T06:11:07.479928Z",
     "iopub.execute_input": "2021-12-24T06:11:07.480177Z",
     "iopub.status.idle": "2021-12-24T06:11:07.484465Z",
     "shell.execute_reply.started": "2021-12-24T06:11:07.480144Z",
     "shell.execute_reply": "2021-12-24T06:11:07.483631Z"
    },
    "trusted": true
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "tokenized_test = test_ds.map(tokenize_for_test)\ntokenized_test",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-24T06:11:07.48597Z",
     "iopub.execute_input": "2021-12-24T06:11:07.486242Z",
     "iopub.status.idle": "2021-12-24T06:11:07.638677Z",
     "shell.execute_reply.started": "2021-12-24T06:11:07.486206Z",
     "shell.execute_reply": "2021-12-24T06:11:07.637886Z"
    },
    "trusted": true
   },
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "0ex [00:00, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "efd76f9d23bf4ae9a44f0612e8d3ecd9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['id', 'text', 'input_ids', 'attention_mask', 'offset_mapping'],\n    num_rows: 5\n})"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "predictions, _, _ = trainer.predict(tokenized_test)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-24T06:11:07.6399Z",
     "iopub.execute_input": "2021-12-24T06:11:07.640218Z",
     "iopub.status.idle": "2021-12-24T06:11:09.048717Z",
     "shell.execute_reply.started": "2021-12-24T06:11:07.640179Z",
     "shell.execute_reply": "2021-12-24T06:11:09.047961Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import numpy as np\n\npreds = np.argmax(predictions, axis=-1)\npredictions.shape, preds.shape",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-24T06:11:09.050017Z",
     "iopub.execute_input": "2021-12-24T06:11:09.050291Z",
     "iopub.status.idle": "2021-12-24T06:11:09.056971Z",
     "shell.execute_reply.started": "2021-12-24T06:11:09.050259Z",
     "shell.execute_reply": "2021-12-24T06:11:09.05609Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "dfs = []\nfor i in range(len(tokenized_test)):\n    dfs.append(pred2span(preds[i], tokenized_test[i], test=True))\n\npred_df = pd.concat(dfs, axis=0)\npred_df['class'] = pred_df['discourse_type']",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-24T06:11:09.058545Z",
     "iopub.execute_input": "2021-12-24T06:11:09.05886Z",
     "iopub.status.idle": "2021-12-24T06:11:09.111088Z",
     "shell.execute_reply.started": "2021-12-24T06:11:09.058824Z",
     "shell.execute_reply": "2021-12-24T06:11:09.1104Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "sub = pred_df[['id', 'class', 'predictionstring']]",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-24T06:11:09.112204Z",
     "iopub.execute_input": "2021-12-24T06:11:09.112484Z",
     "iopub.status.idle": "2021-12-24T06:11:09.118286Z",
     "shell.execute_reply.started": "2021-12-24T06:11:09.112451Z",
     "shell.execute_reply": "2021-12-24T06:11:09.117511Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "sub.to_csv('submission.csv', index=False)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-24T06:11:09.121513Z",
     "iopub.execute_input": "2021-12-24T06:11:09.121771Z",
     "iopub.status.idle": "2021-12-24T06:11:09.13022Z",
     "shell.execute_reply.started": "2021-12-24T06:11:09.121737Z",
     "shell.execute_reply": "2021-12-24T06:11:09.129455Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}