{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# HuggingFace Inference Baseline\n\nTraining notebook: https://www.kaggle.com/thedrcat/feedback-prize-huggingface-baseline-training","metadata":{}},{"cell_type":"code","source":"# Config\nbatch_size = 1\nmin_tokens = 5\ntok_checkpoint = '../input/longformer/model'\nmodel_checkpoint = '../input/feedback-prize-huggingface-baseline-training/longformer-base-4096-4/pytorch_model.bin'","metadata":{"execution":{"iopub.status.busy":"2021-12-24T06:10:33.53461Z","iopub.execute_input":"2021-12-24T06:10:33.534874Z","iopub.status.idle":"2021-12-24T06:10:33.540694Z","shell.execute_reply.started":"2021-12-24T06:10:33.534844Z","shell.execute_reply":"2021-12-24T06:10:33.538986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load data\nimport pandas as pd\n\ntrain = pd.read_csv('../input/feedback-prize-2021/train.csv')\ntrain.head(1)\n\ntest = pd.read_csv('../input/feedback-prize-2021/sample_submission.csv')\ntest.head(1)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T06:10:34.007753Z","iopub.execute_input":"2021-12-24T06:10:34.00816Z","iopub.status.idle":"2021-12-24T06:10:35.81608Z","shell.execute_reply.started":"2021-12-24T06:10:34.008122Z","shell.execute_reply":"2021-12-24T06:10:35.815223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setup dictionaries\nclasses = train.discourse_type.unique().tolist()\n\nfrom collections import defaultdict\n\ntags = defaultdict()\nfor i, c in enumerate(classes):\n    tags[f'B-{c}'] = i\n    tags[f'I-{c}'] = i + len(classes)\ntags[f'O'] = len(classes) * 2\ntags[f'Special'] = -100\nl2i = dict(tags)\n\ni2l = defaultdict()\nfor k, v in l2i.items(): \n    i2l[v] = k\ni2l[-100] = 'Special'\ni2l = dict(i2l)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T06:10:35.817956Z","iopub.execute_input":"2021-12-24T06:10:35.818285Z","iopub.status.idle":"2021-12-24T06:10:35.845445Z","shell.execute_reply.started":"2021-12-24T06:10:35.818248Z","shell.execute_reply":"2021-12-24T06:10:35.844633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Helper functions\nfrom pathlib import Path\n\ntest_path = Path('../input/feedback-prize-2021/test')\n\ndef get_test_text(ids):\n    with open(test_path/f'{ids}.txt', 'r') as file: data = file.read()\n    return data","metadata":{"execution":{"iopub.status.busy":"2021-12-24T06:10:35.847276Z","iopub.execute_input":"2021-12-24T06:10:35.847583Z","iopub.status.idle":"2021-12-24T06:10:35.853177Z","shell.execute_reply.started":"2021-12-24T06:10:35.847547Z","shell.execute_reply":"2021-12-24T06:10:35.852277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenizer\nfrom transformers import AutoTokenizer\n    \ntokenizer = AutoTokenizer.from_pretrained(tok_checkpoint, add_prefix_space=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T06:10:38.408127Z","iopub.execute_input":"2021-12-24T06:10:38.408862Z","iopub.status.idle":"2021-12-24T06:10:45.190207Z","shell.execute_reply.started":"2021-12-24T06:10:38.408823Z","shell.execute_reply":"2021-12-24T06:10:45.189449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load model\nfrom transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\nimport torch\n\nmodel = AutoModelForTokenClassification.from_pretrained(tok_checkpoint, num_labels=len(i2l)-1)\n\nmodel.load_state_dict(torch.load(model_checkpoint))\nmodel.eval();","metadata":{"execution":{"iopub.status.busy":"2021-12-24T06:10:45.19514Z","iopub.execute_input":"2021-12-24T06:10:45.196841Z","iopub.status.idle":"2021-12-24T06:11:06.430638Z","shell.execute_reply.started":"2021-12-24T06:10:45.196795Z","shell.execute_reply":"2021-12-24T06:11:06.429865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import DataCollatorForTokenClassification\n\ndata_collator = DataCollatorForTokenClassification(tokenizer)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T06:11:06.431861Z","iopub.execute_input":"2021-12-24T06:11:06.43376Z","iopub.status.idle":"2021-12-24T06:11:06.439251Z","shell.execute_reply.started":"2021-12-24T06:11:06.433718Z","shell.execute_reply":"2021-12-24T06:11:06.437151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We'll use trainer with the loaded model to run inference on test set\ntrainer = Trainer(\n    model,\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T06:11:06.441463Z","iopub.execute_input":"2021-12-24T06:11:06.442026Z","iopub.status.idle":"2021-12-24T06:11:07.396345Z","shell.execute_reply.started":"2021-12-24T06:11:06.441988Z","shell.execute_reply":"2021-12-24T06:11:07.395494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# code that will convert our predictions into prediction strings. we'll skip visualization here. \n# this most likely requires some refactoring\n\ndef get_class(c):\n    if c == 14: return 'Other'\n    else: return i2l[c][2:]\n\ndef pred2span(pred, example, viz=False, test=False):\n    example_id = example['id']\n    n_tokens = len(example['input_ids'])\n    classes = []\n    all_span = []\n    for i, c in enumerate(pred.tolist()):\n        if i == n_tokens-1:\n            break\n        if i == 0:\n            cur_span = example['offset_mapping'][i]\n            classes.append(get_class(c))\n        elif i > 0 and (c == pred[i-1] or (c-7) == pred[i-1]):\n            cur_span[1] = example['offset_mapping'][i][1]\n        else:\n            all_span.append(cur_span)\n            cur_span = example['offset_mapping'][i]\n            classes.append(get_class(c))\n    all_span.append(cur_span)\n    \n    if test: text = get_test_text(example_id)\n    else: text = get_raw_text(example_id)\n        \n    # map token ids to word (whitespace) token ids\n    predstrings = []\n    for span in all_span:\n        span_start = span[0]\n        span_end = span[1]\n        before = text[:span_start]\n        token_start = len(before.split())\n        if len(before) == 0: token_start = 0\n        elif before[-1] != ' ': token_start -= 1\n        num_tkns = len(text[span_start:span_end+1].split())\n        tkns = [str(x) for x in range(token_start, token_start+num_tkns)]\n        predstring = ' '.join(tkns)\n        predstrings.append(predstring)\n                    \n    rows = []\n    for c, span, predstring in zip(classes, all_span, predstrings):\n        e = {\n            'id': example_id,\n            'discourse_type': c,\n            'predictionstring': predstring,\n            'discourse_start': span[0],\n            'discourse_end': span[1],\n            'discourse': text[span[0]:span[1]+1]\n        }\n        rows.append(e)\n\n\n    df = pd.DataFrame(rows)\n    df['length'] = df['discourse'].apply(lambda t: len(t.split()))\n    \n    # short spans are likely to be false positives, we can choose a min number of tokens based on validation\n    df = df[df.length > min_tokens].reset_index(drop=True)\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-12-24T06:11:07.400847Z","iopub.execute_input":"2021-12-24T06:11:07.401127Z","iopub.status.idle":"2021-12-24T06:11:07.41777Z","shell.execute_reply.started":"2021-12-24T06:11:07.401098Z","shell.execute_reply":"2021-12-24T06:11:07.417021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load test data\nimport os \n\nfiles = os.listdir('../input/feedback-prize-2021/test')\nids = [x.split('.')[0] for x in files]\n\ndf_test = pd.DataFrame()\ndf_test['id'] = ids\ndf_test['text'] = df_test['id'].apply(get_test_text)\ndf_test","metadata":{"execution":{"iopub.status.busy":"2021-12-24T06:11:07.419548Z","iopub.execute_input":"2021-12-24T06:11:07.420148Z","iopub.status.idle":"2021-12-24T06:11:07.454812Z","shell.execute_reply.started":"2021-12-24T06:11:07.42011Z","shell.execute_reply":"2021-12-24T06:11:07.454201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\n\ntest_ds = Dataset.from_pandas(df_test)\ntest_ds","metadata":{"execution":{"iopub.status.busy":"2021-12-24T06:11:07.456311Z","iopub.execute_input":"2021-12-24T06:11:07.456689Z","iopub.status.idle":"2021-12-24T06:11:07.47858Z","shell.execute_reply.started":"2021-12-24T06:11:07.456656Z","shell.execute_reply":"2021-12-24T06:11:07.477801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenize_for_test(examples):\n\n    o = tokenizer(examples['text'], truncation=True, return_offsets_mapping=True, max_length=4096)\n  \n    return o","metadata":{"execution":{"iopub.status.busy":"2021-12-24T06:11:07.479928Z","iopub.execute_input":"2021-12-24T06:11:07.480177Z","iopub.status.idle":"2021-12-24T06:11:07.484465Z","shell.execute_reply.started":"2021-12-24T06:11:07.480144Z","shell.execute_reply":"2021-12-24T06:11:07.483631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_test = test_ds.map(tokenize_for_test)\ntokenized_test","metadata":{"execution":{"iopub.status.busy":"2021-12-24T06:11:07.48597Z","iopub.execute_input":"2021-12-24T06:11:07.486242Z","iopub.status.idle":"2021-12-24T06:11:07.638677Z","shell.execute_reply.started":"2021-12-24T06:11:07.486206Z","shell.execute_reply":"2021-12-24T06:11:07.637886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions, _, _ = trainer.predict(tokenized_test)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T06:11:07.6399Z","iopub.execute_input":"2021-12-24T06:11:07.640218Z","iopub.status.idle":"2021-12-24T06:11:09.048717Z","shell.execute_reply.started":"2021-12-24T06:11:07.640179Z","shell.execute_reply":"2021-12-24T06:11:09.047961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\npreds = np.argmax(predictions, axis=-1)\npredictions.shape, preds.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-24T06:11:09.050017Z","iopub.execute_input":"2021-12-24T06:11:09.050291Z","iopub.status.idle":"2021-12-24T06:11:09.056971Z","shell.execute_reply.started":"2021-12-24T06:11:09.050259Z","shell.execute_reply":"2021-12-24T06:11:09.05609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfs = []\nfor i in range(len(tokenized_test)):\n    dfs.append(pred2span(preds[i], tokenized_test[i], test=True))\n\npred_df = pd.concat(dfs, axis=0)\npred_df['class'] = pred_df['discourse_type']","metadata":{"execution":{"iopub.status.busy":"2021-12-24T06:11:09.058545Z","iopub.execute_input":"2021-12-24T06:11:09.05886Z","iopub.status.idle":"2021-12-24T06:11:09.111088Z","shell.execute_reply.started":"2021-12-24T06:11:09.058824Z","shell.execute_reply":"2021-12-24T06:11:09.1104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pred_df[['id', 'class', 'predictionstring']]","metadata":{"execution":{"iopub.status.busy":"2021-12-24T06:11:09.112204Z","iopub.execute_input":"2021-12-24T06:11:09.112484Z","iopub.status.idle":"2021-12-24T06:11:09.118286Z","shell.execute_reply.started":"2021-12-24T06:11:09.112451Z","shell.execute_reply":"2021-12-24T06:11:09.117511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T06:11:09.121513Z","iopub.execute_input":"2021-12-24T06:11:09.121771Z","iopub.status.idle":"2021-12-24T06:11:09.13022Z","shell.execute_reply.started":"2021-12-24T06:11:09.121737Z","shell.execute_reply":"2021-12-24T06:11:09.129455Z"},"trusted":true},"execution_count":null,"outputs":[]}]}