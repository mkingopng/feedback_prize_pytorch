{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "goal: make the notebooks from kaggle look mroe like the standard huggingface approach and eliminate all the errors?\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb_creds import *\n",
    "\n",
    "wandb.login(key=API_KEY)\n",
    "wandb.init(project=\"feedback_prize_pytorch\", tags=TAGS, entity=\"feedback_prize_michael_and_wilson\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# CONFIG\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "EXP_NUM = 1\n",
    "TASK = \"ner\"\n",
    "MODEL_CHECKPOINT = \"longformer-base-4096-hf\"\n",
    "MAX_LENGTH = 1024\n",
    "STRIDE = 128\n",
    "MIN_TOKENS = 6\n",
    "MODEL_PATH = f'{MODEL_CHECKPOINT.split(\"/\")[-1]}-{EXP_NUM}'\n",
    "DATA_DIR = 'data'\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
    "TRAIN_DF = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))\n",
    "\n",
    "# TRAINING HYPERPARAMS\n",
    "BATCH_SIZE = 8\n",
    "GRAD_ACC = 8\n",
    "LEARNING_RATE = 5e-5\n",
    "WEIGHT_DECAY = 0.01\n",
    "WARMUP = 0.1\n",
    "N_EPOCHS = 5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# read train data\n",
    "TRAIN_DF.head(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check unique classes\n",
    "CLASSES = TRAIN_DF.discourse_type.unique().tolist()\n",
    "CLASSES"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# setup label indices\n",
    "from collections import defaultdict\n",
    "\n",
    "tags = defaultdict()\n",
    "\n",
    "for i, c in enumerate(CLASSES):\n",
    "    tags[f'B-{c}'] = i\n",
    "    tags[f'I-{c}'] = i + len(CLASSES)\n",
    "tags[f'O'] = len(CLASSES) * 2\n",
    "tags[f'Special'] = -100\n",
    "\n",
    "l2i = dict(tags)\n",
    "\n",
    "i2l = defaultdict()\n",
    "for k, v in l2i.items():\n",
    "    i2l[v] = k\n",
    "i2l[-100] = 'Special'\n",
    "\n",
    "i2l = dict(i2l)\n",
    "\n",
    "N_LABELS = len(i2l) - 1 # not accounting for -100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_raw_text(ids):\n",
    "    with open(TRAIN_DIR/f'{ids}.txt', 'r') as file: data = file.read()\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# group training labels by text file\n",
    "df1 = TRAIN_DF.groupby('id')['discourse_type'].apply(list).reset_index(name='classlist')\n",
    "df2 = TRAIN_DF.groupby('id')['discourse_start'].apply(list).reset_index(name='starts')\n",
    "df3 = TRAIN_DF.groupby('id')['discourse_end'].apply(list).reset_index(name='ends')\n",
    "df4 = TRAIN_DF.groupby('id')['predictionstring'].apply(list).reset_index(name='predictionstrings')\n",
    "df = pd.merge(df1, df2, how='inner', on='id')\n",
    "df = pd.merge(df, df3, how='inner', on='id')\n",
    "df = pd.merge(df, df4, how='inner', on='id')\n",
    "df['text'] = df['id'].apply(get_raw_text)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# we will use HuggingFace datasets\n",
    "from datasets import Dataset, load_metric\n",
    "\n",
    "ds = Dataset.from_pandas(df)\n",
    "datasets = ds.train_test_split(test_size=0.1, shuffle=True, seed=42)\n",
    "datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "[0, 7, 7, 7, 1, 1, 8, 8, 8, 2, 9, 9, 14, 4, 4, 4]"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not sure if this is needed, but in case we create a span with certain class without starting token of that class,\n",
    "# let's convert the first token to be the starting token.\n",
    "\n",
    "e = [0, 7, 7, 7, 1, 1, 8, 8, 8, 9, 9, 9, 14, 4, 4, 4]\n",
    "\n",
    "def set_beginning(labels):\n",
    "    for i in range(1,len(labels)):\n",
    "        curr_lab = labels[i]\n",
    "        prev_lab = labels[i-1]\n",
    "        if curr_lab in range(7,14):\n",
    "            if prev_lab != curr_lab and prev_lab != curr_lab - 7:\n",
    "                labels[i] = curr_lab -7\n",
    "    return labels\n",
    "\n",
    "set_beginning(labels=e)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer, DataCollatorForTokenClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT, add_prefix_space=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# tokenize and add labels\n",
    "def tokenize_and_align_labels(examples):\n",
    "    o = tokenizer(examples['text'], truncation=True, padding=True, return_offsets_mapping=True, max_length=max_length, stride=stride, return_overflowing_tokens=True)\n",
    "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
    "    # its corresponding example. This key gives us just that.\n",
    "    sample_mapping = o[\"overflow_to_sample_mapping\"]\n",
    "    # The offset mappings will give us a map from token to character position in the original context. This will\n",
    "    # help us compute the start_positions and end_positions.\n",
    "    offset_mapping = o[\"offset_mapping\"]\n",
    "    o[\"labels\"] = []\n",
    "    for i in range(len(offset_mapping))\n",
    "        sample_index = sample_mapping[i]\n",
    "        labels = [l2i['O'] for i in range(len(o['input_ids'][i]))]\n",
    "        for label_start, label_end, label in \\\n",
    "        list(zip(examples['starts'][sample_index], examples['ends'][sample_index], examples['classlist'][sample_index])):\n",
    "            for j in range(len(labels)):\n",
    "                token_start = offset_mapping[i][j][0]\n",
    "                token_end = offset_mapping[i][j][1]\n",
    "                if token_start == label_start:\n",
    "                    labels[j] = l2i[f'B-{label}']\n",
    "                if token_start > label_start and token_end <= label_end:\n",
    "                    labels[j] = l2i[f'I-{label}']\n",
    "        for k, input_id in enumerate(o['input_ids'][i]):\n",
    "            if input_id in [0,1,2]:\n",
    "                labels[k] = -100\n",
    "        labels = set_beginning(labels)\n",
    "        o[\"labels\"].append(labels)\n",
    "\n",
    "    return o"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#\n",
    "tokenized_datasets = datasets.map(tokenize_and_align_labels, batched=True, batch_size=20000, remove_columns=datasets[\"train\"].column_names)\n",
    "tokenized_datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# we will use auto model for token classification\n",
    "model = AutoModelForTokenClassification.from_pretrained(MODEL_CHECKPOINT, num_labels=N_LABELS)\n",
    "model_name = MODEL_CHECKPOINT.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-{TASK}\",  #\n",
    "    evaluation_strategy = \"epoch\",  # evaluation is done at the end of each epoch\n",
    "    logging_strategy = \"epoch\",  # logging is done at the end of each epoch. consider \"steps\".\n",
    "    logging_first_step=True, # whether to log and evaluate the first global step or not\n",
    "    save_strategy = \"epoch\",  # saving is done at the end of each epoch\n",
    "    learning_rate=LEARNING_RATE,  # the initial learning rate for AdamW optimizer\n",
    "    per_device_train_batch_size=BATCH_SIZE,  # the batch size per device\n",
    "    per_device_eval_batch_size=BATCH_SIZE,  # the batch size per device\n",
    "    num_train_epochs=N_EPOCHS,  # default=3. the number of training epochs\n",
    "    weight_decay=WEIGHT_DECAY,  # Default=0. The weight decay to apply to all layers except all bias and LayerNorm weights in AdamW optimizer\n",
    "    report_to='wandb', #\n",
    "    adam_beta1=0.9,  # default=0.9. The beta1 hyperparameter for the AdamW optimizer\n",
    "    adam_beta2=0.999,  # default=0.999. The beta2 hyperparameter for the AdamW optimizer\n",
    "    adam_epsilon=1e-8,  # default=1e-8. the epsilon hyperparameter for the AdamW optimizer.\n",
    "    max_grad_norm=1,  # default=1, maximum gradient norm (for gradient clipping).\n",
    "    lr_scheduler_type=\"linear\", # default=\"linear\". the scheduler type to use. Consider get_cosine_scheduler_with_warmup()\n",
    "    gradient_accumulation_steps=GRAD_ACC,  # default=1. the number of updates steps to accumulate gradients for before performing a backward/update pass.\n",
    "    warmup_ratio=WARMUP,  # ratio of total training steps used for a linear warnup from 0 to learning rate\n",
    "    seed=42,  # random seed that will be used at the beginning of training. TO ensure reproducability use the model_init() function to instantiate the nodel if it has some randomly initialize parameters.\n",
    ")\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# data collators are objects that will form a batch by using a list of dataset elements as input. These elements are of the same type as the elements of train_dataset() or eval_dataset(). Data collators may apply some processing (like padding) or random data augmentation (like random masking)\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(\n",
    "    tokenizer=tokenizer,  # the tokenizer used for encoding the data\n",
    "    return_tensors='pt', # the type of tensor to return\n",
    "    label_pad_token_id=-100, # default. the padding id to use when padding the labels\n",
    "    padding=True  # strategy to pad the sequence. True = pad to the longest sequence in the batch.\n",
    ")\n",
    "data_collator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# this is not the competition metric, but for now this will be better than nothing...\n",
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [i2l[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [i2l[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n",
    "\n",
    "# The compute function needs to receive a tuple (with logits and labels) and has to return a dictionary with string keys (the name of the metric) and float values. It will be called at the end of each evaluation phase on the whole arrays of predictions/labels."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,  # defined above\n",
    "    args=args,  # defined above\n",
    "    train_dataset=tokenized_datasets[\"train\"],  # this is kinda set\n",
    "    eval_dataset=tokenized_datasets[\"test\"],  # this is kinda set\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,  # defined above. I think this can be improved.\n",
    "    compute_metrics=compute_metrics,  # defined above. seems like a placeholder\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")  # new addition\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(args.num_train_epochs))\n",
    "\n",
    "trainer.train()  #\n",
    "for epoch in range(args.num_train_epochs):\n",
    "    for batch in data_collator:\n",
    "          batch = {k: v.to(device) for k, v in batch.items()}\n",
    "          outputs = model.(**batch)\n",
    "          args.loss = outputs.loss\n",
    "          args.loss.backward()\n",
    "          args.optimizer.step()\n",
    "          args.lr_scheduler.step()\n",
    "          args.optimizer.zero_grad()\n",
    "          progress_bar.update(1)\n",
    "wandb.log({\"train-loss\": 0.5, \"accuracy\": 0.9})  # new additions. most basic\n",
    "wandb.watch(model)  # new additions\n",
    "wandb.finish()  #"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sequences = [pass]  # mk: what do I put here?\n",
    "\n",
    "batch = tokenizer(sequences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "batch['labels'] = torch.tensor([1, 1])  # mk: how to determine the correct value to put here?\n",
    "\n",
    "optimizer  = torch.optim.AdamW(model.parameters)\n",
    "\n",
    "loss = model(**batch).loss\n",
    "loss.backward()\n",
    "optimizer.step()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AdamW, AutoModelForTokenClassification"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}