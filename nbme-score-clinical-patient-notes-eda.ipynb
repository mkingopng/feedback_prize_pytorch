{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-13T12:27:30.145081Z","iopub.execute_input":"2022-02-13T12:27:30.146115Z","iopub.status.idle":"2022-02-13T12:27:30.178168Z","shell.execute_reply.started":"2022-02-13T12:27:30.145992Z","shell.execute_reply":"2022-02-13T12:27:30.177172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n!pip install textstat\n\nimport numpy as np\nimport pandas as pd \nimport os\nimport re\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nltk\nimport textstat\nimport spacy\nnlp = spacy.load('en_core_web_sm')\n\nfrom termcolor import colored\nfrom wordcloud import WordCloud,STOPWORDS\nfrom spacy import displacy\nfrom nltk.tokenize import sent_tokenize, word_tokenize \n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-02-13T12:27:30.180187Z","iopub.execute_input":"2022-02-13T12:27:30.180886Z","iopub.status.idle":"2022-02-13T12:27:56.99983Z","shell.execute_reply.started":"2022-02-13T12:27:30.180829Z","shell.execute_reply":"2022-02-13T12:27:56.998713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"patient_notes = pd.read_csv('/kaggle/input/nbme-score-clinical-patient-notes/patient_notes.csv')\nfeatures = pd.read_csv('/kaggle/input/nbme-score-clinical-patient-notes/features.csv')\ntrain = pd.read_csv('/kaggle/input/nbme-score-clinical-patient-notes/train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-02-13T12:27:57.001381Z","iopub.execute_input":"2022-02-13T12:27:57.001635Z","iopub.status.idle":"2022-02-13T12:27:57.903702Z","shell.execute_reply.started":"2022-02-13T12:27:57.001605Z","shell.execute_reply":"2022-02-13T12:27:57.902729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"patient_notes.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T12:27:57.906371Z","iopub.execute_input":"2022-02-13T12:27:57.90672Z","iopub.status.idle":"2022-02-13T12:27:57.928056Z","shell.execute_reply.started":"2022-02-13T12:27:57.906676Z","shell.execute_reply":"2022-02-13T12:27:57.927427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"patient_notes['pn_history'][0]","metadata":{"execution":{"iopub.status.busy":"2022-02-13T12:27:57.934297Z","iopub.execute_input":"2022-02-13T12:27:57.934778Z","iopub.status.idle":"2022-02-13T12:27:57.943259Z","shell.execute_reply.started":"2022-02-13T12:27:57.934744Z","shell.execute_reply":"2022-02-13T12:27:57.942301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T12:27:57.944801Z","iopub.execute_input":"2022-02-13T12:27:57.945083Z","iopub.status.idle":"2022-02-13T12:27:57.961494Z","shell.execute_reply.started":"2022-02-13T12:27:57.945055Z","shell.execute_reply":"2022-02-13T12:27:57.960543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T12:27:57.963366Z","iopub.execute_input":"2022-02-13T12:27:57.963685Z","iopub.status.idle":"2022-02-13T12:27:57.980032Z","shell.execute_reply.started":"2022-02-13T12:27:57.963649Z","shell.execute_reply":"2022-02-13T12:27:57.979183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features.nunique()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T12:27:57.98226Z","iopub.execute_input":"2022-02-13T12:27:57.982495Z","iopub.status.idle":"2022-02-13T12:27:57.993275Z","shell.execute_reply.started":"2022-02-13T12:27:57.982466Z","shell.execute_reply":"2022-02-13T12:27:57.992597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"patient_notes.nunique()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T12:27:57.994322Z","iopub.execute_input":"2022-02-13T12:27:57.994549Z","iopub.status.idle":"2022-02-13T12:27:58.120118Z","shell.execute_reply.started":"2022-02-13T12:27:57.99452Z","shell.execute_reply":"2022-02-13T12:27:58.119089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.nunique()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T12:27:58.12172Z","iopub.execute_input":"2022-02-13T12:27:58.122056Z","iopub.status.idle":"2022-02-13T12:27:58.144203Z","shell.execute_reply.started":"2022-02-13T12:27:58.122012Z","shell.execute_reply":"2022-02-13T12:27:58.143532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def patient_data(pn_num):\n    subset = train[train['pn_num'] == pn_num]\n    \n    features_lst = subset['feature_num'].tolist()\n    annotations_lst = subset['annotation'].tolist()\n    \n    subset_c = subset.copy()\n    subset_c['location'] = subset_c['location'].apply(eval)\n    subset_c['annotation'] = subset_c['annotation'].apply(eval)\n    locations  = subset_c[\"location\"]\n    annotations = subset_c[\"annotation\"]\n    \n    print(\"*\"*80)\n    print(colored(\"Patient Number: \" + str(pn_num), 'green'))\n    patient_history = patient_notes[patient_notes['pn_num']==pn_num]['pn_history'].item()\n    \n    print(colored(\"\\nAnnotated Patient History\", 'green'))\n    \n    ents = []\n    for location in locations:\n        for i in range(len(location)):\n            for loc in location:\n                val = loc.split()\n                ents.append({\n                'start': int(val[0]), \n                'end' :  int(val[1]),\n                'label' : \"Annotation\"\n                })\n    ents = sorted(ents, key = lambda i: i['start'])\n\n    doc = {\n        'text' : patient_history,\n        'ents' : ents\n    }\n    colors = {\"Annotation\" :\"linear-gradient(to right, #2980b9, #6dd5fa, #ffffff);\" } \n    options = {\"colors\": colors}\n    spacy.displacy.render(doc, style='ent', options = options , manual=True, jupyter=True);\n    \n    print(colored(\"\\nVisualizing NER\", 'green'))\n    doc = nlp(patient_history)\n    displacy.render(doc, style='ent', jupyter = True)\n    \n    \"\"\"print(colored(\"\\nVisualizing POS tagging\", 'green'))\n    sentences = sent_tokenize(patient_history)\n    word_count = lambda sentence: len(word_tokenize(sentence))\n    pos_text = max(sentences, key=word_count)  \n    doc = nlp(pos_text)\n    displacy.render(doc, style=\"dep\")\"\"\"\n\n    print(colored(\"\\nFeatures\", 'green'))\n    for feature_num in features_lst:\n        feature = features[features['feature_num'] == feature_num]['feature_text'][feature_num]\n        print(colored(feature, 'blue'))\n        \npatient_data(352)\npatient_data(46)\npatient_data(100)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T12:27:58.145963Z","iopub.execute_input":"2022-02-13T12:27:58.146241Z","iopub.status.idle":"2022-02-13T12:27:58.412722Z","shell.execute_reply.started":"2022-02-13T12:27:58.146201Z","shell.execute_reply":"2022-02-13T12:27:58.411478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def color_wc(word=None,font_size=None,position=None, orientation=None,font_path=None, random_state=None):\n    h = int(360.0 * 150.0 / 255.0)\n    s = int(100.0 * 255.0 / 255.0)\n    l = int(100.0 * float(random_state.randint(80, 120)) / 255.0)\n    return \"hsl({}, {}%, {}%)\".format(h, s, l)\n\ndef create_wordcloud(df, col):\n    print(colored(col, 'green'))\n    plt.subplots(figsize=(16,16))\n    wc = WordCloud(stopwords=STOPWORDS,background_color=\"white\", contour_width=2, contour_color='blue',width=1500, height=750,color_func=color_wc,max_words=150, max_font_size=256,random_state=42)\n    wc.generate(' '.join(df[col]))\n    plt.imshow(wc, interpolation=\"bilinear\")\n    plt.axis('off')\n    plt.show()\n    \ncreate_wordcloud(train, 'annotation')\ncreate_wordcloud(features, 'feature_text')\ncreate_wordcloud(patient_notes, 'pn_history')\n","metadata":{"execution":{"iopub.status.busy":"2022-02-13T12:27:58.41409Z","iopub.execute_input":"2022-02-13T12:27:58.41446Z","iopub.status.idle":"2022-02-13T12:28:27.336503Z","shell.execute_reply.started":"2022-02-13T12:27:58.414424Z","shell.execute_reply":"2022-02-13T12:28:27.33558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def patient_data(pn_num):\n    subset = train[train['pn_num'] == pn_num]\n    \n    features_lst = subset['feature_num'].tolist()\n    annotations_lst = subset['annotation'].tolist()\n    \n    subset_c = subset.copy()\n    subset_c['location'] = subset_c['location'].apply(eval)\n    subset_c['annotation'] = subset_c['annotation'].apply(eval)\n    locations  = subset_c[\"location\"]\n    annotations = subset_c[\"annotation\"]\n    \n    print(\"*\"*80)\n    print(colored(\"Patient Number: \" + str(pn_num), 'green'))\n    patient_history = patient_notes[patient_notes['pn_num']==pn_num]['pn_history'].item()\n    \n    for feature_num in features_lst:\n        feature = features[features['feature_num'] == feature_num]['feature_text'][feature_num]\n        \n        print(feature)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T12:40:37.057042Z","iopub.execute_input":"2022-02-13T12:40:37.057396Z","iopub.status.idle":"2022-02-13T12:40:37.066848Z","shell.execute_reply.started":"2022-02-13T12:40:37.057362Z","shell.execute_reply":"2022-02-13T12:40:37.065897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"patient_data(46)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T12:40:38.445659Z","iopub.execute_input":"2022-02-13T12:40:38.445984Z","iopub.status.idle":"2022-02-13T12:40:38.466255Z","shell.execute_reply.started":"2022-02-13T12:40:38.445953Z","shell.execute_reply":"2022-02-13T12:40:38.46561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}