{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# This one works now, so best not change it. Keep it as a reference point"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# HuggingFace Training Baseline\n",
    "\n",
    "I wanted to create my own baseline for this competition, and I tried to do so \"without peeking\" at the kernels published by others. Ideally this can be used for training on a Kaggle kernel. Let's see how good we can get.\n",
    "\n",
    "This baseline is based on the following notebook by Sylvain Gugger: https://github.com/huggingface/notebooks/blob/master/examples/token_classification.ipynb\n",
    "\n",
    "I initially started building with Roberta - thanks to Chris Deotte for pointing to Longformer :) The evaluation code is from Rob Mulla.\n",
    "\n",
    "The notebook requires a couple of hours to run, so we'll use W&B to be able to monitor it along the way and keep the record of our experiments."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "SAMPLE = False # set True for debugging"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-23T22:59:40.43361Z",
     "iopub.execute_input": "2021-12-23T22:59:40.434Z",
     "iopub.status.idle": "2021-12-23T22:59:40.438896Z",
     "shell.execute_reply.started": "2021-12-23T22:59:40.433966Z",
     "shell.execute_reply": "2021-12-23T22:59:40.437857Z"
    },
    "trusted": true
   },
   "execution_count": 54,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# !pip install seqeval -qq # evaluation metrics for training (not the competition metric)\n",
    "# !pip install --upgrade wandb -qq # experiment tracking"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-23T22:59:40.441479Z",
     "iopub.execute_input": "2021-12-23T22:59:40.442112Z",
     "iopub.status.idle": "2021-12-23T23:00:00.091404Z",
     "shell.execute_reply.started": "2021-12-23T22:59:40.442065Z",
     "shell.execute_reply": "2021-12-23T23:00:00.090244Z"
    },
    "trusted": true
   },
   "execution_count": 55,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# setup wandb for experiment tracking\n",
    "# source: https://www.kaggle.com/debarshichanda/pytorch-w-b-jigsaw-starter\n",
    "\n",
    "import wandb\n",
    "\n",
    "# try:\n",
    "#     from kaggle_secrets import UserSecretsClient\n",
    "#     user_secrets = UserSecretsClient()\n",
    "#     api_key = user_secrets.get_secret(\"wandb_api\")\n",
    "#     wandb.login(key=api_key)\n",
    "#     wandb.init(project=\"feedback_prize\", entity=\"darek\")\n",
    "#     anony = None\n",
    "# except:\n",
    "#     anony = \"must\"\n",
    "#     print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-23T23:00:00.094757Z",
     "iopub.execute_input": "2021-12-23T23:00:00.095189Z",
     "iopub.status.idle": "2021-12-23T23:00:08.865381Z",
     "shell.execute_reply.started": "2021-12-23T23:00:00.095139Z",
     "shell.execute_reply": "2021-12-23T23:00:08.86421Z"
    },
    "trusted": true
   },
   "execution_count": 56,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Finishing last run (ID:2xk73gtx) before initializing another..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 12090... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c59ffd88023b408ab9e2eff566bcf7e1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆█▆▆</td></tr><tr><td>eval/f1</td><td>▁▃▆██</td></tr><tr><td>eval/loss</td><td>█▂▁▄▅</td></tr><tr><td>eval/precision</td><td>▁▃▆██</td></tr><tr><td>eval/recall</td><td>▁▃▆██</td></tr><tr><td>eval/runtime</td><td>▂▂▁▇█</td></tr><tr><td>eval/samples_per_second</td><td>▇▇█▂▁</td></tr><tr><td>eval/steps_per_second</td><td>▇▇█▂▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▅▅▆▆███</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▅▅▆▆███</td></tr><tr><td>train/learning_rate</td><td>█▆▅▃▁</td></tr><tr><td>train/loss</td><td>█▄▂▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.81236</td></tr><tr><td>eval/f1</td><td>0.25839</td></tr><tr><td>eval/loss</td><td>0.60252</td></tr><tr><td>eval/precision</td><td>0.20447</td></tr><tr><td>eval/recall</td><td>0.35093</td></tr><tr><td>eval/runtime</td><td>47.7363</td></tr><tr><td>eval/samples_per_second</td><td>34.041</td></tr><tr><td>eval/steps_per_second</td><td>8.526</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>2275</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.3771</td></tr><tr><td>train/total_flos</td><td>4.759569086688461e+16</td></tr><tr><td>train/train_loss</td><td>0.5694</td></tr><tr><td>train/train_runtime</td><td>7425.9189</td></tr><tr><td>train/train_samples_per_second</td><td>9.813</td></tr><tr><td>train/train_steps_per_second</td><td>0.306</td></tr></table>\n</div></div>\nSynced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">confused-bird-42</strong>: <a href=\"https://wandb.ai/feedback_prize_michael_and_wilson/feedback_prize_pytorch/runs/2xk73gtx\" target=\"_blank\">https://wandb.ai/feedback_prize_michael_and_wilson/feedback_prize_pytorch/runs/2xk73gtx</a><br/>\nFind logs at: <code>./wandb/run-20220301_102321-2xk73gtx/logs</code><br/>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Successfully finished last run (ID:2xk73gtx). Initializing new run:<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    Syncing run <strong><a href=\"https://wandb.ai/feedback_prize_michael_and_wilson/feedback_prize_pytorch/runs/1ulziezx\" target=\"_blank\">warm-star-43</a></strong> to <a href=\"https://wandb.ai/feedback_prize_michael_and_wilson/feedback_prize_pytorch\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n\n                "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/feedback_prize_michael_and_wilson/feedback_prize_pytorch/runs/1ulziezx?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>",
      "text/plain": "<wandb.sdk.wandb_run.Run at 0x7ff489010bb0>"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb_creds import *\n",
    "\n",
    "wandb.login(key=API_KEY)\n",
    "wandb.init(project=\"feedback_prize_pytorch\", tags=TAGS, entity=\"feedback_prize_michael_and_wilson\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# CONFIG\n",
    "\n",
    "EXP_NUM = 1\n",
    "task = \"ner\"\n",
    "model_checkpoint = \"longformer-base-4096-hf\"\n",
    "max_length = 1024\n",
    "stride = 128\n",
    "min_tokens = 6\n",
    "model_path = f'{model_checkpoint.split(\"/\")[-1]}-{EXP_NUM}'\n",
    "\n",
    "# TRAINING HYPERPARAMS\n",
    "BS = 4\n",
    "GRAD_ACC = 8\n",
    "LR = 5e-5\n",
    "WD = 0.01\n",
    "WARMUP = 0.1\n",
    "N_EPOCHS = 5"
   ],
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.status.busy": "2021-12-23T23:00:08.872471Z",
     "iopub.execute_input": "2021-12-23T23:00:08.875384Z",
     "iopub.status.idle": "2021-12-23T23:00:09.613866Z",
     "shell.execute_reply.started": "2021-12-23T23:00:08.875328Z",
     "shell.execute_reply": "2021-12-23T23:00:09.612856Z"
    },
    "trusted": true
   },
   "execution_count": 58,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read train data\n",
    "train = pd.read_csv('data/train.csv')\n",
    "train.head(1)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-23T23:00:09.615125Z",
     "iopub.execute_input": "2021-12-23T23:00:09.615508Z",
     "iopub.status.idle": "2021-12-23T23:00:11.240349Z",
     "shell.execute_reply.started": "2021-12-23T23:00:09.615458Z",
     "shell.execute_reply": "2021-12-23T23:00:11.239275Z"
    },
    "trusted": true
   },
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "             id  discourse_id  discourse_start  discourse_end  \\\n0  423A1CA112E2  1.622628e+12              8.0          229.0   \n\n                                      discourse_text discourse_type  \\\n0  Modern humans today are always on their phone....           Lead   \n\n  discourse_type_num                                   predictionstring  \n0             Lead 1  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>discourse_id</th>\n      <th>discourse_start</th>\n      <th>discourse_end</th>\n      <th>discourse_text</th>\n      <th>discourse_type</th>\n      <th>discourse_type_num</th>\n      <th>predictionstring</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>423A1CA112E2</td>\n      <td>1.622628e+12</td>\n      <td>8.0</td>\n      <td>229.0</td>\n      <td>Modern humans today are always on their phone....</td>\n      <td>Lead</td>\n      <td>Lead 1</td>\n      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# check unique classes\n",
    "classes = train.discourse_type.unique().tolist()\n",
    "classes"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-23T23:00:11.245598Z",
     "iopub.execute_input": "2021-12-23T23:00:11.248663Z",
     "iopub.status.idle": "2021-12-23T23:00:12.088646Z",
     "shell.execute_reply.started": "2021-12-23T23:00:11.248611Z",
     "shell.execute_reply": "2021-12-23T23:00:12.087709Z"
    },
    "trusted": true
   },
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "['Lead',\n 'Position',\n 'Evidence',\n 'Claim',\n 'Concluding Statement',\n 'Counterclaim',\n 'Rebuttal']"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# setup label indices\n",
    "from collections import defaultdict\n",
    "\n",
    "tags = defaultdict()\n",
    "\n",
    "for i, c in enumerate(classes):\n",
    "    tags[f'B-{c}'] = i\n",
    "    tags[f'I-{c}'] = i + len(classes)\n",
    "tags[f'O'] = len(classes) * 2\n",
    "tags[f'Special'] = -100\n",
    "    \n",
    "l2i = dict(tags)\n",
    "\n",
    "i2l = defaultdict()\n",
    "for k, v in l2i.items(): \n",
    "    i2l[v] = k\n",
    "i2l[-100] = 'Special'\n",
    "\n",
    "i2l = dict(i2l)\n",
    "\n",
    "N_LABELS = len(i2l) - 1 # not accounting for -100"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-23T23:00:12.090074Z",
     "iopub.execute_input": "2021-12-23T23:00:12.090401Z",
     "iopub.status.idle": "2021-12-23T23:00:12.909927Z",
     "shell.execute_reply.started": "2021-12-23T23:00:12.090357Z",
     "shell.execute_reply": "2021-12-23T23:00:12.908979Z"
    },
    "trusted": true
   },
   "execution_count": 61,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# some helper functions\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "path = Path('data/train')\n",
    "\n",
    "def get_raw_text(ids):\n",
    "    with open(path/f'{ids}.txt', 'r') as file: data = file.read()\n",
    "    return data"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-23T23:00:12.913651Z",
     "iopub.execute_input": "2021-12-23T23:00:12.913893Z",
     "iopub.status.idle": "2021-12-23T23:00:13.630498Z",
     "shell.execute_reply.started": "2021-12-23T23:00:12.913861Z",
     "shell.execute_reply": "2021-12-23T23:00:13.629554Z"
    },
    "trusted": true
   },
   "execution_count": 62,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# group training labels by text file\n",
    "\n",
    "df1 = train.groupby('id')['discourse_type'].apply(list).reset_index(name='classlist')\n",
    "df2 = train.groupby('id')['discourse_start'].apply(list).reset_index(name='starts')\n",
    "df3 = train.groupby('id')['discourse_end'].apply(list).reset_index(name='ends')\n",
    "df4 = train.groupby('id')['predictionstring'].apply(list).reset_index(name='predictionstrings')\n",
    "\n",
    "df = pd.merge(df1, df2, how='inner', on='id')\n",
    "df = pd.merge(df, df3, how='inner', on='id')\n",
    "df = pd.merge(df, df4, how='inner', on='id')\n",
    "df['text'] = df['id'].apply(get_raw_text)\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-23T23:00:13.634902Z",
     "iopub.execute_input": "2021-12-23T23:00:13.635138Z",
     "iopub.status.idle": "2021-12-23T23:00:24.829274Z",
     "shell.execute_reply.started": "2021-12-23T23:00:13.635107Z",
     "shell.execute_reply": "2021-12-23T23:00:24.828189Z"
    },
    "trusted": true
   },
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "             id                                          classlist  \\\n0  0000D23A521A  [Position, Evidence, Evidence, Claim, Counterc...   \n1  00066EA9880D  [Lead, Position, Claim, Evidence, Claim, Evide...   \n2  000E6DE9E817  [Position, Counterclaim, Rebuttal, Evidence, C...   \n3  001552828BD0  [Lead, Evidence, Claim, Claim, Evidence, Claim...   \n4  0016926B079C  [Position, Claim, Claim, Claim, Claim, Evidenc...   \n\n                                              starts  \\\n0  [0.0, 170.0, 358.0, 438.0, 627.0, 722.0, 836.0...   \n1  [0.0, 456.0, 638.0, 738.0, 1399.0, 1488.0, 231...   \n2  [17.0, 64.0, 158.0, 310.0, 438.0, 551.0, 776.0...   \n3  [0.0, 161.0, 872.0, 958.0, 1191.0, 1542.0, 161...   \n4  [0.0, 58.0, 94.0, 206.0, 236.0, 272.0, 542.0, ...   \n\n                                                ends  \\\n0  [170.0, 357.0, 438.0, 626.0, 722.0, 836.0, 101...   \n1  [455.0, 592.0, 738.0, 1398.0, 1487.0, 2219.0, ...   \n2  [56.0, 157.0, 309.0, 422.0, 551.0, 775.0, 961....   \n3  [160.0, 872.0, 957.0, 1190.0, 1541.0, 1612.0, ...   \n4  [57.0, 91.0, 150.0, 235.0, 271.0, 542.0, 650.0...   \n\n                                   predictionstrings  \\\n0  [0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 1...   \n1  [0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 1...   \n2  [2 3 4 5 6 7 8, 10 11 12 13 14 15 16 17 18 19 ...   \n3  [0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 1...   \n4  [0 1 2 3 4 5 6 7 8 9, 10 11 12 13 14 15, 16 17...   \n\n                                                text  \n0  Some people belive that the so called \"face\" o...  \n1  Driverless cars are exaclty what you would exp...  \n2  Dear: Principal\\n\\nI am arguing against the po...  \n3  Would you be able to give your car up? Having ...  \n4  I think that students would benefit from learn...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>classlist</th>\n      <th>starts</th>\n      <th>ends</th>\n      <th>predictionstrings</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000D23A521A</td>\n      <td>[Position, Evidence, Evidence, Claim, Counterc...</td>\n      <td>[0.0, 170.0, 358.0, 438.0, 627.0, 722.0, 836.0...</td>\n      <td>[170.0, 357.0, 438.0, 626.0, 722.0, 836.0, 101...</td>\n      <td>[0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 1...</td>\n      <td>Some people belive that the so called \"face\" o...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00066EA9880D</td>\n      <td>[Lead, Position, Claim, Evidence, Claim, Evide...</td>\n      <td>[0.0, 456.0, 638.0, 738.0, 1399.0, 1488.0, 231...</td>\n      <td>[455.0, 592.0, 738.0, 1398.0, 1487.0, 2219.0, ...</td>\n      <td>[0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 1...</td>\n      <td>Driverless cars are exaclty what you would exp...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000E6DE9E817</td>\n      <td>[Position, Counterclaim, Rebuttal, Evidence, C...</td>\n      <td>[17.0, 64.0, 158.0, 310.0, 438.0, 551.0, 776.0...</td>\n      <td>[56.0, 157.0, 309.0, 422.0, 551.0, 775.0, 961....</td>\n      <td>[2 3 4 5 6 7 8, 10 11 12 13 14 15 16 17 18 19 ...</td>\n      <td>Dear: Principal\\n\\nI am arguing against the po...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>001552828BD0</td>\n      <td>[Lead, Evidence, Claim, Claim, Evidence, Claim...</td>\n      <td>[0.0, 161.0, 872.0, 958.0, 1191.0, 1542.0, 161...</td>\n      <td>[160.0, 872.0, 957.0, 1190.0, 1541.0, 1612.0, ...</td>\n      <td>[0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 1...</td>\n      <td>Would you be able to give your car up? Having ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0016926B079C</td>\n      <td>[Position, Claim, Claim, Claim, Claim, Evidenc...</td>\n      <td>[0.0, 58.0, 94.0, 206.0, 236.0, 272.0, 542.0, ...</td>\n      <td>[57.0, 91.0, 150.0, 235.0, 271.0, 542.0, 650.0...</td>\n      <td>[0 1 2 3 4 5 6 7 8 9, 10 11 12 13 14 15, 16 17...</td>\n      <td>I think that students would benefit from learn...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# debugging\n",
    "if SAMPLE: df = df.sample(n=100).reset_index(drop=True)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-23T23:00:24.831063Z",
     "iopub.execute_input": "2021-12-23T23:00:24.831421Z",
     "iopub.status.idle": "2021-12-23T23:00:25.596595Z",
     "shell.execute_reply.started": "2021-12-23T23:00:24.831375Z",
     "shell.execute_reply": "2021-12-23T23:00:25.595633Z"
    },
    "trusted": true
   },
   "execution_count": 64,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# we will use HuggingFace datasets\n",
    "from datasets import Dataset, load_metric\n",
    "\n",
    "ds = Dataset.from_pandas(df)\n",
    "datasets = ds.train_test_split(test_size=0.1, shuffle=True, seed=42)\n",
    "datasets"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-23T23:00:25.59961Z",
     "iopub.execute_input": "2021-12-23T23:00:25.600322Z",
     "iopub.status.idle": "2021-12-23T23:00:26.415085Z",
     "shell.execute_reply.started": "2021-12-23T23:00:25.600259Z",
     "shell.execute_reply": "2021-12-23T23:00:26.413987Z"
    },
    "trusted": true
   },
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['id', 'classlist', 'starts', 'ends', 'predictionstrings', 'text', '__index_level_0__'],\n        num_rows: 14034\n    })\n    test: Dataset({\n        features: ['id', 'classlist', 'starts', 'ends', 'predictionstrings', 'text', '__index_level_0__'],\n        num_rows: 1560\n    })\n})"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-23T23:00:26.416852Z",
     "iopub.execute_input": "2021-12-23T23:00:26.417192Z",
     "iopub.status.idle": "2021-12-23T23:00:31.722501Z",
     "shell.execute_reply.started": "2021-12-23T23:00:26.417127Z",
     "shell.execute_reply": "2021-12-23T23:00:31.721572Z"
    },
    "trusted": true
   },
   "execution_count": 66,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file longformer-base-4096-hf/config.json\n",
      "Model config LongformerConfig {\n",
      "  \"_name_or_path\": \"longformer-base-4096-hf\",\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Didn't find file longformer-base-4096-hf/added_tokens.json. We won't load it.\n",
      "Didn't find file longformer-base-4096-hf/special_tokens_map.json. We won't load it.\n",
      "Didn't find file longformer-base-4096-hf/tokenizer_config.json. We won't load it.\n",
      "loading file longformer-base-4096-hf/vocab.json\n",
      "loading file longformer-base-4096-hf/merges.txt\n",
      "loading file longformer-base-4096-hf/tokenizer.json\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "loading configuration file longformer-base-4096-hf/config.json\n",
      "Model config LongformerConfig {\n",
      "  \"_name_or_path\": \"longformer-base-4096-hf\",\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Not sure if this is needed, but in case we create a span with certain class without starting token of that class,\n",
    "# let's convert the first token to be the starting token.\n",
    "\n",
    "e = [0,7,7,7,1,1,8,8,8,9,9,9,14,4,4,4]\n",
    "\n",
    "def fix_beginnings(labels):\n",
    "    for i in range(1,len(labels)):\n",
    "        curr_lab = labels[i]\n",
    "        prev_lab = labels[i-1]\n",
    "        if curr_lab in range(7,14):\n",
    "            if prev_lab != curr_lab and prev_lab != curr_lab - 7:\n",
    "                labels[i] = curr_lab -7\n",
    "    return labels\n",
    "\n",
    "fix_beginnings(e)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-23T23:00:31.724112Z",
     "iopub.execute_input": "2021-12-23T23:00:31.724482Z",
     "iopub.status.idle": "2021-12-23T23:00:32.494243Z",
     "shell.execute_reply.started": "2021-12-23T23:00:31.724438Z",
     "shell.execute_reply": "2021-12-23T23:00:32.49297Z"
    },
    "trusted": true
   },
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "[0, 7, 7, 7, 1, 1, 8, 8, 8, 2, 9, 9, 14, 4, 4, 4]"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# tokenize and add labels\n",
    "def tokenize_and_align_labels(examples):\n",
    "\n",
    "    o = tokenizer(examples['text'], truncation=True, padding=True, return_offsets_mapping=True, max_length=max_length, stride=stride, return_overflowing_tokens=True)\n",
    "\n",
    "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
    "    # its corresponding example. This key gives us just that.\n",
    "    sample_mapping = o[\"overflow_to_sample_mapping\"]\n",
    "\n",
    "    # The offset mappings will give us a map from token to character position in the original context. This will\n",
    "    # help us compute the start_positions and end_positions.\n",
    "    offset_mapping = o[\"offset_mapping\"]\n",
    "    \n",
    "    o[\"labels\"] = []\n",
    "\n",
    "    for i in range(len(offset_mapping)):\n",
    "                   \n",
    "        sample_index = sample_mapping[i]\n",
    "\n",
    "        labels = [l2i['O'] for i in range(len(o['input_ids'][i]))]\n",
    "\n",
    "        for label_start, label_end, label in \\\n",
    "        list(zip(examples['starts'][sample_index], examples['ends'][sample_index], examples['classlist'][sample_index])):\n",
    "            for j in range(len(labels)):\n",
    "                token_start = offset_mapping[i][j][0]\n",
    "                token_end = offset_mapping[i][j][1]\n",
    "                if token_start == label_start: \n",
    "                    labels[j] = l2i[f'B-{label}']    \n",
    "                if token_start > label_start and token_end <= label_end: \n",
    "                    labels[j] = l2i[f'I-{label}']\n",
    "\n",
    "        for k, input_id in enumerate(o['input_ids'][i]):\n",
    "            if input_id in [0,1,2]:\n",
    "                labels[k] = -100\n",
    "\n",
    "        labels = fix_beginnings(labels)\n",
    "                   \n",
    "        o[\"labels\"].append(labels)\n",
    "        \n",
    "    return o"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-23T23:00:32.495836Z",
     "iopub.execute_input": "2021-12-23T23:00:32.496208Z",
     "iopub.status.idle": "2021-12-23T23:00:33.263669Z",
     "shell.execute_reply.started": "2021-12-23T23:00:32.49614Z",
     "shell.execute_reply": "2021-12-23T23:00:33.262629Z"
    },
    "trusted": true
   },
   "execution_count": 68,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tokenized_datasets = datasets.map(tokenize_and_align_labels, batched=True, batch_size=20000, remove_columns=datasets[\"train\"].column_names)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-23T23:00:33.265142Z",
     "iopub.execute_input": "2021-12-23T23:00:33.265646Z",
     "iopub.status.idle": "2021-12-23T23:00:35.856612Z",
     "shell.execute_reply.started": "2021-12-23T23:00:33.265601Z",
     "shell.execute_reply": "2021-12-23T23:00:35.855589Z"
    },
    "trusted": true
   },
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "73754f1984664a889d621c69074060a3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "829cc7f9f0da4aa4961d7e731e545cdc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "tokenized_datasets"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-23T23:00:35.858326Z",
     "iopub.execute_input": "2021-12-23T23:00:35.858635Z",
     "iopub.status.idle": "2021-12-23T23:00:36.592654Z",
     "shell.execute_reply.started": "2021-12-23T23:00:35.85859Z",
     "shell.execute_reply": "2021-12-23T23:00:36.591606Z"
    },
    "trusted": true
   },
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask', 'offset_mapping', 'overflow_to_sample_mapping', 'labels'],\n        num_rows: 14574\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask', 'offset_mapping', 'overflow_to_sample_mapping', 'labels'],\n        num_rows: 1625\n    })\n})"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model and Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# we will use auto model for token classification\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=N_LABELS)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-23T23:00:36.59433Z",
     "iopub.execute_input": "2021-12-23T23:00:36.594634Z",
     "iopub.status.idle": "2021-12-23T23:00:40.685632Z",
     "shell.execute_reply.started": "2021-12-23T23:00:36.594593Z",
     "shell.execute_reply": "2021-12-23T23:00:40.684693Z"
    },
    "trusted": true
   },
   "execution_count": 71,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file longformer-base-4096-hf/config.json\n",
      "Model config LongformerConfig {\n",
      "  \"_name_or_path\": \"longformer-base-4096-hf\",\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\"\n",
      "  },\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file longformer-base-4096-hf/pytorch_model.bin\n",
      "Some weights of the model checkpoint at longformer-base-4096-hf were not used when initializing LongformerForTokenClassification: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForTokenClassification were not initialized from the model checkpoint at longformer-base-4096-hf and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-{task}\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    logging_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=LR,\n",
    "    per_device_train_batch_size=BS,\n",
    "    per_device_eval_batch_size=BS,\n",
    "    num_train_epochs=N_EPOCHS,\n",
    "    weight_decay=WD,\n",
    "    report_to='wandb', \n",
    "    gradient_accumulation_steps=GRAD_ACC,\n",
    "    warmup_ratio=WARMUP\n",
    ")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-23T23:00:40.690854Z",
     "iopub.execute_input": "2021-12-23T23:00:40.693718Z",
     "iopub.status.idle": "2021-12-23T23:00:41.535273Z",
     "shell.execute_reply.started": "2021-12-23T23:00:40.693672Z",
     "shell.execute_reply": "2021-12-23T23:00:41.534215Z"
    },
    "trusted": true
   },
   "execution_count": 72,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-23T23:00:41.53676Z",
     "iopub.execute_input": "2021-12-23T23:00:41.537608Z",
     "iopub.status.idle": "2021-12-23T23:00:42.282789Z",
     "shell.execute_reply.started": "2021-12-23T23:00:41.537572Z",
     "shell.execute_reply": "2021-12-23T23:00:42.281853Z"
    },
    "trusted": true
   },
   "execution_count": 73,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# this is not the competition metric, but for now this will be better than nothing...\n",
    "\n",
    "metric = load_metric(\"seqeval\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-23T23:00:42.284192Z",
     "iopub.execute_input": "2021-12-23T23:00:42.284501Z",
     "iopub.status.idle": "2021-12-23T23:00:43.656933Z",
     "shell.execute_reply.started": "2021-12-23T23:00:42.284458Z",
     "shell.execute_reply": "2021-12-23T23:00:43.655937Z"
    },
    "trusted": true
   },
   "execution_count": 74,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [i2l[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [i2l[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-23T23:00:43.658571Z",
     "iopub.execute_input": "2021-12-23T23:00:43.658881Z",
     "iopub.status.idle": "2021-12-23T23:00:44.386693Z",
     "shell.execute_reply.started": "2021-12-23T23:00:43.658824Z",
     "shell.execute_reply": "2021-12-23T23:00:44.385607Z"
    },
    "trusted": true
   },
   "execution_count": 75,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics, \n",
    ")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-23T23:00:44.388421Z",
     "iopub.execute_input": "2021-12-23T23:00:44.388744Z",
     "iopub.status.idle": "2021-12-23T23:00:45.313179Z",
     "shell.execute_reply.started": "2021-12-23T23:00:44.38869Z",
     "shell.execute_reply": "2021-12-23T23:00:45.312215Z"
    },
    "trusted": true
   },
   "execution_count": 76,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")  # new addition\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/5 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "de322c9bf4354b5b9ed342b672404eee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(args.num_train_epochs))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "trainer.train()  #\n",
    "# for epoch in range(args.num_train_epochs):\n",
    "#     for batch in train_dataloader:\n",
    "#           batch = {k: v.to(device) for k, v in batch.items()}\n",
    "#           outputss = model.(**batch)\n",
    "#           loss = outputs.loss\n",
    "#           loss.backward()\n",
    "#           optimizer.step()\n",
    "#           lr_scheduler.step()\n",
    "#           optimizer.zero_grad()\n",
    "#           progress_bar.update(1)\n",
    "# wandb.log()  # new additions\n",
    "# wandb.watch(model)  # new additions\n",
    "wandb.finish()  #"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-23T23:00:45.314663Z",
     "iopub.execute_input": "2021-12-23T23:00:45.318411Z",
     "iopub.status.idle": "2021-12-23T23:03:13.651205Z",
     "shell.execute_reply.started": "2021-12-23T23:00:45.318345Z",
     "shell.execute_reply": "2021-12-23T23:03:13.650259Z"
    },
    "trusted": true
   },
   "execution_count": 79,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `LongformerForTokenClassification.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping.\n",
      "/home/noone/anaconda3/envs/pytorch_NLP/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 14574\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 8\n",
      "  Total optimization steps = 2275\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='2275' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   2/2275 : < :, Epoch 0.00/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `LongformerForTokenClassification.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1625\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to longformer-base-4096-hf-finetuned-ner/checkpoint-455\n",
      "Configuration saved in longformer-base-4096-hf-finetuned-ner/checkpoint-455/config.json\n",
      "Model weights saved in longformer-base-4096-hf-finetuned-ner/checkpoint-455/pytorch_model.bin\n",
      "tokenizer config file saved in longformer-base-4096-hf-finetuned-ner/checkpoint-455/tokenizer_config.json\n",
      "Special tokens file saved in longformer-base-4096-hf-finetuned-ner/checkpoint-455/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `LongformerForTokenClassification.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1625\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to longformer-base-4096-hf-finetuned-ner/checkpoint-910\n",
      "Configuration saved in longformer-base-4096-hf-finetuned-ner/checkpoint-910/config.json\n",
      "Model weights saved in longformer-base-4096-hf-finetuned-ner/checkpoint-910/pytorch_model.bin\n",
      "tokenizer config file saved in longformer-base-4096-hf-finetuned-ner/checkpoint-910/tokenizer_config.json\n",
      "Special tokens file saved in longformer-base-4096-hf-finetuned-ner/checkpoint-910/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `LongformerForTokenClassification.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1625\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to longformer-base-4096-hf-finetuned-ner/checkpoint-1365\n",
      "Configuration saved in longformer-base-4096-hf-finetuned-ner/checkpoint-1365/config.json\n",
      "Model weights saved in longformer-base-4096-hf-finetuned-ner/checkpoint-1365/pytorch_model.bin\n",
      "tokenizer config file saved in longformer-base-4096-hf-finetuned-ner/checkpoint-1365/tokenizer_config.json\n",
      "Special tokens file saved in longformer-base-4096-hf-finetuned-ner/checkpoint-1365/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `LongformerForTokenClassification.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1625\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to longformer-base-4096-hf-finetuned-ner/checkpoint-1820\n",
      "Configuration saved in longformer-base-4096-hf-finetuned-ner/checkpoint-1820/config.json\n",
      "Model weights saved in longformer-base-4096-hf-finetuned-ner/checkpoint-1820/pytorch_model.bin\n",
      "tokenizer config file saved in longformer-base-4096-hf-finetuned-ner/checkpoint-1820/tokenizer_config.json\n",
      "Special tokens file saved in longformer-base-4096-hf-finetuned-ner/checkpoint-1820/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `LongformerForTokenClassification.forward` and have been ignored: overflow_to_sample_mapping, offset_mapping.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1625\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to longformer-base-4096-hf-finetuned-ner/checkpoint-2275\n",
      "Configuration saved in longformer-base-4096-hf-finetuned-ner/checkpoint-2275/config.json\n",
      "Model weights saved in longformer-base-4096-hf-finetuned-ner/checkpoint-2275/pytorch_model.bin\n",
      "tokenizer config file saved in longformer-base-4096-hf-finetuned-ner/checkpoint-2275/tokenizer_config.json\n",
      "Special tokens file saved in longformer-base-4096-hf-finetuned-ner/checkpoint-2275/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 34063... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2d4d0f152e4a4aaab86d382004255ded"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\">\n<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▇█▅▅</td></tr><tr><td>eval/f1</td><td>▁▆▇▇█</td></tr><tr><td>eval/loss</td><td>█▂▁▄▅</td></tr><tr><td>eval/precision</td><td>▁▆▇▇█</td></tr><tr><td>eval/recall</td><td>▁▆▇▇█</td></tr><tr><td>eval/runtime</td><td>▇▇▄▁█</td></tr><tr><td>eval/samples_per_second</td><td>▂▂▅█▁</td></tr><tr><td>eval/steps_per_second</td><td>▂▂▅█▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▅▅▆▆███</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▅▅▆▆███</td></tr><tr><td>train/learning_rate</td><td>█▆▅▃▁</td></tr><tr><td>train/loss</td><td>█▃▂▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.81181</td></tr><tr><td>eval/f1</td><td>0.27188</td></tr><tr><td>eval/loss</td><td>0.59758</td></tr><tr><td>eval/precision</td><td>0.21863</td></tr><tr><td>eval/recall</td><td>0.35941</td></tr><tr><td>eval/runtime</td><td>46.5542</td></tr><tr><td>eval/samples_per_second</td><td>34.906</td></tr><tr><td>eval/steps_per_second</td><td>8.742</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>2275</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.383</td></tr><tr><td>train/total_flos</td><td>4.759569086688461e+16</td></tr><tr><td>train/train_loss</td><td>0.57609</td></tr><tr><td>train/train_runtime</td><td>7428.2038</td></tr><tr><td>train/train_samples_per_second</td><td>9.81</td></tr><tr><td>train/train_steps_per_second</td><td>0.306</td></tr></table>\n</div></div>\nSynced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n<br/>Synced <strong style=\"color:#cdcd00\">warm-star-43</strong>: <a href=\"https://wandb.ai/feedback_prize_michael_and_wilson/feedback_prize_pytorch/runs/1ulziezx\" target=\"_blank\">https://wandb.ai/feedback_prize_michael_and_wilson/feedback_prize_pytorch/runs/1ulziezx</a><br/>\nFind logs at: <code>./wandb/run-20220301_125707-1ulziezx/logs</code><br/>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "trainer.save_model(model_path)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-23T23:03:13.656546Z",
     "iopub.execute_input": "2021-12-23T23:03:13.656788Z",
     "iopub.status.idle": "2021-12-23T23:03:15.317965Z",
     "shell.execute_reply.started": "2021-12-23T23:03:13.656757Z",
     "shell.execute_reply": "2021-12-23T23:03:15.316868Z"
    },
    "trusted": true
   },
   "execution_count": 80,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to longformer-base-4096-hf-1\n",
      "Configuration saved in longformer-base-4096-hf-1/config.json\n",
      "Model weights saved in longformer-base-4096-hf-1/pytorch_model.bin\n",
      "tokenizer config file saved in longformer-base-4096-hf-1/tokenizer_config.json\n",
      "Special tokens file saved in longformer-base-4096-hf-1/special_tokens_map.json\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Validation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def tokenize_for_validation(examples):\n",
    "\n",
    "    o = tokenizer(examples['text'], truncation=True, return_offsets_mapping=True, max_length=4096)\n",
    "\n",
    "    # The offset mappings will give us a map from token to character position in the original context. This will\n",
    "    # help us compute the start_positions and end_positions.\n",
    "    offset_mapping = o[\"offset_mapping\"]\n",
    "    \n",
    "    o[\"labels\"] = []\n",
    "\n",
    "    for i in range(len(offset_mapping)):\n",
    "                   \n",
    "        labels = [l2i['O'] for i in range(len(o['input_ids'][i]))]\n",
    "\n",
    "        for label_start, label_end, label in \\\n",
    "        list(zip(examples['starts'][i], examples['ends'][i], examples['classlist'][i])):\n",
    "            for j in range(len(labels)):\n",
    "                token_start = offset_mapping[i][j][0]\n",
    "                token_end = offset_mapping[i][j][1]\n",
    "                if token_start == label_start: \n",
    "                    labels[j] = l2i[f'B-{label}']    \n",
    "                if token_start > label_start and token_end <= label_end: \n",
    "                    labels[j] = l2i[f'I-{label}']\n",
    "\n",
    "        for k, input_id in enumerate(o['input_ids'][i]):\n",
    "            if input_id in [0,1,2]:\n",
    "                labels[k] = -100\n",
    "\n",
    "        labels = fix_beginnings(labels)\n",
    "                   \n",
    "        o[\"labels\"].append(labels)\n",
    "        \n",
    "    return o"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-23T23:03:15.31952Z",
     "iopub.execute_input": "2021-12-23T23:03:15.319834Z",
     "iopub.status.idle": "2021-12-23T23:03:15.332639Z",
     "shell.execute_reply.started": "2021-12-23T23:03:15.319782Z",
     "shell.execute_reply": "2021-12-23T23:03:15.331235Z"
    },
    "trusted": true
   },
   "execution_count": 81,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tokenized_val = datasets.map(tokenize_for_validation, batched=True)\n",
    "tokenized_val"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-23T23:03:15.334494Z",
     "iopub.execute_input": "2021-12-23T23:03:15.335669Z",
     "iopub.status.idle": "2021-12-23T23:03:16.652272Z",
     "shell.execute_reply.started": "2021-12-23T23:03:15.335596Z",
     "shell.execute_reply": "2021-12-23T23:03:16.651209Z"
    },
    "trusted": true
   },
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/15 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6aed4a6b8dfb44a4b91e18f05a0638fd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "656b13806bba460bb2a3c52d62b66f8e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['id', 'classlist', 'starts', 'ends', 'predictionstrings', 'text', '__index_level_0__', 'input_ids', 'attention_mask', 'offset_mapping', 'labels'],\n        num_rows: 14034\n    })\n    test: Dataset({\n        features: ['id', 'classlist', 'starts', 'ends', 'predictionstrings', 'text', '__index_level_0__', 'input_ids', 'attention_mask', 'offset_mapping', 'labels'],\n        num_rows: 1560\n    })\n})"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# ground truth for validation\n",
    "\n",
    "l = []\n",
    "for example in tokenized_val['test']:\n",
    "    for c, p in list(zip(example['classlist'], example['predictionstrings'])):\n",
    "        l.append({\n",
    "            'id': example['id'],\n",
    "            'discourse_type': c,\n",
    "            'predictionstring': p,\n",
    "        })\n",
    "    \n",
    "gt_df = pd.DataFrame(l)\n",
    "gt_df"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-23T23:03:16.654017Z",
     "iopub.execute_input": "2021-12-23T23:03:16.654625Z",
     "iopub.status.idle": "2021-12-23T23:03:16.711036Z",
     "shell.execute_reply.started": "2021-12-23T23:03:16.654567Z",
     "shell.execute_reply": "2021-12-23T23:03:16.710012Z"
    },
    "trusted": true
   },
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "                 id        discourse_type  \\\n0      7B5F5B33B566                  Lead   \n1      7B5F5B33B566              Position   \n2      7B5F5B33B566              Evidence   \n3      7B5F5B33B566                 Claim   \n4      7B5F5B33B566              Evidence   \n...             ...                   ...   \n14461  B3E4B633261B                 Claim   \n14462  B3E4B633261B              Evidence   \n14463  B3E4B633261B          Counterclaim   \n14464  B3E4B633261B              Rebuttal   \n14465  B3E4B633261B  Concluding Statement   \n\n                                        predictionstring  \n0      0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...  \n1      43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 5...  \n2      69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 8...  \n3      166 167 168 169 170 171 172 173 174 175 176 17...  \n4      180 181 182 183 184 185 186 187 188 189 190 19...  \n...                                                  ...  \n14461  94 95 96 97 98 99 100 101 102 103 104 105 106 ...  \n14462  113 114 115 116 117 118 119 120 121 122 123 12...  \n14463                        126 127 128 129 130 131 132  \n14464  133 134 135 136 137 138 139 140 141 142 143 14...  \n14465  147 148 149 150 151 152 153 154 155 156 157 15...  \n\n[14466 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>discourse_type</th>\n      <th>predictionstring</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7B5F5B33B566</td>\n      <td>Lead</td>\n      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7B5F5B33B566</td>\n      <td>Position</td>\n      <td>43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 5...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7B5F5B33B566</td>\n      <td>Evidence</td>\n      <td>69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 8...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7B5F5B33B566</td>\n      <td>Claim</td>\n      <td>166 167 168 169 170 171 172 173 174 175 176 17...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7B5F5B33B566</td>\n      <td>Evidence</td>\n      <td>180 181 182 183 184 185 186 187 188 189 190 19...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>14461</th>\n      <td>B3E4B633261B</td>\n      <td>Claim</td>\n      <td>94 95 96 97 98 99 100 101 102 103 104 105 106 ...</td>\n    </tr>\n    <tr>\n      <th>14462</th>\n      <td>B3E4B633261B</td>\n      <td>Evidence</td>\n      <td>113 114 115 116 117 118 119 120 121 122 123 12...</td>\n    </tr>\n    <tr>\n      <th>14463</th>\n      <td>B3E4B633261B</td>\n      <td>Counterclaim</td>\n      <td>126 127 128 129 130 131 132</td>\n    </tr>\n    <tr>\n      <th>14464</th>\n      <td>B3E4B633261B</td>\n      <td>Rebuttal</td>\n      <td>133 134 135 136 137 138 139 140 141 142 143 14...</td>\n    </tr>\n    <tr>\n      <th>14465</th>\n      <td>B3E4B633261B</td>\n      <td>Concluding Statement</td>\n      <td>147 148 149 150 151 152 153 154 155 156 157 15...</td>\n    </tr>\n  </tbody>\n</table>\n<p>14466 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# visualization with displacy\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from pylab import cm, matplotlib\n",
    "\n",
    "# this bit throw an error"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-23T23:03:16.712458Z",
     "iopub.execute_input": "2021-12-23T23:03:16.713221Z",
     "iopub.status.idle": "2021-12-23T23:03:16.719502Z",
     "shell.execute_reply.started": "2021-12-23T23:03:16.713168Z",
     "shell.execute_reply": "2021-12-23T23:03:16.718212Z"
    },
    "trusted": true
   },
   "execution_count": 84,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'srsly' has no attribute 'read_yaml'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_7417/486643345.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mpathlib\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mPath\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mspacy\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mspacy\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mdisplacy\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mpylab\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mcm\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmatplotlib\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch_NLP/lib/python3.9/site-packages/spacy/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mpipeline\u001B[0m  \u001B[0;31m# noqa: F401\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mcli\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minfo\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0minfo\u001B[0m  \u001B[0;31m# noqa: F401\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mglossary\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mexplain\u001B[0m  \u001B[0;31m# noqa: F401\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mabout\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0m__version__\u001B[0m  \u001B[0;31m# noqa: F401\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch_NLP/lib/python3.9/site-packages/spacy/cli/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mconvert\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mconvert\u001B[0m  \u001B[0;31m# noqa: F401\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0minit_pipeline\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0minit_pipeline_cli\u001B[0m  \u001B[0;31m# noqa: F401\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 20\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0minit_config\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0minit_config\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfill_config\u001B[0m  \u001B[0;31m# noqa: F401\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     21\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mvalidate\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mvalidate\u001B[0m  \u001B[0;31m# noqa: F401\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mproject\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclone\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mproject_clone\u001B[0m  \u001B[0;31m# noqa: F401\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch_NLP/lib/python3.9/site-packages/spacy/cli/init_config.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[0mROOT\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mPath\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m__file__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparent\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0;34m\"templates\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[0mTEMPLATE_PATH\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mROOT\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0;34m\"quickstart_training.jinja\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 19\u001B[0;31m \u001B[0mRECOMMENDATIONS\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msrsly\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_yaml\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mROOT\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0;34m\"quickstart_training_recommendations.yml\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     20\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'srsly' has no attribute 'read_yaml'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "path = Path('data/train')\n",
    "\n",
    "colors = {\n",
    "            'Lead': '#8000ff',\n",
    "            'Position': '#2b7ff6',\n",
    "            'Evidence': '#2adddd',\n",
    "            'Claim': '#80ffb4',\n",
    "            'Concluding Statement': 'd4dd80',\n",
    "            'Counterclaim': '#ff8042',\n",
    "            'Rebuttal': '#ff0000',\n",
    "            'Other': '#007f00',\n",
    "         }\n",
    "\n",
    "def visualize(df, text):\n",
    "    ents = []\n",
    "    example = df['id'].loc[0]\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        ents.append({\n",
    "                        'start': int(row['discourse_start']), \n",
    "                         'end': int(row['discourse_end']), \n",
    "                         'label': row['discourse_type']\n",
    "                    })\n",
    "\n",
    "    doc2 = {\n",
    "        \"text\": text,\n",
    "        \"ents\": ents,\n",
    "        \"title\": example\n",
    "    }\n",
    "\n",
    "    options = {\"ents\": train.discourse_type.unique().tolist() + ['Other'], \"colors\": colors}\n",
    "    displacy.render(doc2, style=\"ent\", options=options, manual=True, jupyter=True)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-23T23:03:16.721142Z",
     "iopub.execute_input": "2021-12-23T23:03:16.721798Z",
     "iopub.status.idle": "2021-12-23T23:03:16.733508Z",
     "shell.execute_reply.started": "2021-12-23T23:03:16.721753Z",
     "shell.execute_reply": "2021-12-23T23:03:16.732443Z"
    },
    "trusted": true
   },
   "execution_count": 85,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "predictions, labels, _ = trainer.predict(tokenized_val['test'])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-23T23:03:16.735115Z",
     "iopub.execute_input": "2021-12-23T23:03:16.736247Z",
     "iopub.status.idle": "2021-12-23T23:03:17.621012Z",
     "shell.execute_reply.started": "2021-12-23T23:03:16.736199Z",
     "shell.execute_reply": "2021-12-23T23:03:17.619921Z"
    },
    "trusted": true
   },
   "execution_count": 86,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `LongformerForTokenClassification.forward` and have been ignored: classlist, predictionstrings, ends, text, __index_level_0__, offset_mapping, id, starts.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1560\n",
      "  Batch size = 4\n",
      "Input ids are automatically padded from 652 to 1024 to be a multiple of `config.attention_window`: 512\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  1/390 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 639 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 710 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 551 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 555 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 816 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1016 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 547 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 665 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 636 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 609 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 448 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 852 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 504 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 774 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 734 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 540 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 757 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 960 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 593 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 673 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 466 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 700 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 396 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 496 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 869 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 928 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 531 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1190 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 871 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 673 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 529 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 516 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1081 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 398 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 667 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 596 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 465 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 515 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 449 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 470 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 904 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1248 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 758 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 550 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 888 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 715 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 733 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 490 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1131 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 777 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 587 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 517 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 704 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 611 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 573 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 955 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 453 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 677 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 557 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 706 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 708 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 791 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 827 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 714 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 545 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1090 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 880 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 895 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 626 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 820 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 350 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 963 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 773 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 967 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 458 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 761 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 462 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 682 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1575 to 2048 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 637 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 430 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 613 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 640 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 574 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 857 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 516 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 713 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 632 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 725 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 678 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 766 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 873 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1273 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 484 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 767 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 553 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 739 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 690 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 705 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 878 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 975 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1175 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 637 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 467 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 696 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 813 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 522 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 777 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 616 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 547 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 704 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 621 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 560 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 943 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 625 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1101 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 584 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 514 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 574 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1027 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 592 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 825 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 534 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 617 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 625 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 504 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 713 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 950 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 841 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 919 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 892 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 847 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 807 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 803 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 829 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 771 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 673 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 819 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 925 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 907 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 562 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 446 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 938 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 937 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1045 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 734 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 895 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 660 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 655 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1342 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1370 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 509 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 886 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 615 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 629 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 808 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 754 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 559 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1068 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 610 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1144 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 859 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 517 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 803 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 624 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 888 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 785 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1238 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 695 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 727 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 973 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 971 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 634 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 574 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 540 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1011 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 404 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 490 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 646 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1265 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 956 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 514 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 719 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1141 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 911 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 565 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 717 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 843 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1085 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 597 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 780 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 575 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 672 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 621 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1462 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 617 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 668 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 618 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 926 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1171 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1334 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 910 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 769 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1099 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 707 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 389 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 641 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 821 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 763 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 727 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1075 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 746 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 713 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1027 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 921 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 572 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 739 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 966 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 682 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1259 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 715 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 934 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1135 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 646 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 641 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 818 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1231 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 957 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 841 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 995 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1023 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 502 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 710 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1141 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 632 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 594 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1212 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 676 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1196 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 569 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 432 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1015 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 656 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 967 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 795 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 543 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 711 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 684 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 663 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 977 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 863 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 629 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 585 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 551 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 549 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 637 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 466 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 814 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1065 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1022 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 631 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 456 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1130 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 742 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 959 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1163 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 576 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 323 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 626 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1225 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 560 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 653 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 543 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 876 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 781 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 837 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1044 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 954 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 624 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 984 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 955 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 690 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 466 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1132 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 630 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 798 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 685 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 456 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 787 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 567 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 948 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 577 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 730 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 946 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 818 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1160 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 567 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 481 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 619 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 639 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 881 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 703 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 389 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 697 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 664 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 635 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 793 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 601 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 825 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 876 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 619 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 562 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1311 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 747 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 827 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 884 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1026 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 715 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 683 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 741 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 895 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 608 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 682 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 852 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1037 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 613 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 773 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 679 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1205 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 737 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 498 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1038 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 724 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 941 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 445 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 343 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 591 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 656 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 533 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 673 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 884 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1097 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 484 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 438 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 370 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1142 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 567 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 594 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 904 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 571 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 800 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 284 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 462 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 483 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 838 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1267 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 860 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 498 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 883 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1116 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 516 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 773 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 677 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 756 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 384 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 786 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 835 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 760 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 806 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 488 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 688 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 668 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 660 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 978 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1271 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 1207 to 1536 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 793 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 696 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 490 to 512 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 725 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 548 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 673 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 707 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 569 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 764 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "Input ids are automatically padded from 900 to 1024 to be a multiple of `config.attention_window`: 512\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "preds = np.argmax(predictions, axis=-1)\n",
    "preds.shape"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-23T23:03:17.622787Z",
     "iopub.execute_input": "2021-12-23T23:03:17.623357Z",
     "iopub.status.idle": "2021-12-23T23:03:17.632659Z",
     "shell.execute_reply.started": "2021-12-23T23:03:17.623297Z",
     "shell.execute_reply": "2021-12-23T23:03:17.631425Z"
    },
    "trusted": true
   },
   "execution_count": 87,
   "outputs": [
    {
     "data": {
      "text/plain": "(1560, 4096)"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# code that will convert our predictions into prediction strings, and visualize it at the same time this most likely requires some refactoring\n",
    "# mk: ummmm yeah....\n",
    "\n",
    "def get_class(c):\n",
    "    if c == 14: return 'Other'\n",
    "    else: return i2l[c][2:]\n",
    "\n",
    "def pred2span(pred, example, viz=False, test=False):\n",
    "    example_id = example['id']\n",
    "    n_tokens = len(example['input_ids'])\n",
    "    classes = []\n",
    "    all_span = []\n",
    "    for i, c in enumerate(pred.tolist()):\n",
    "        if i == n_tokens-1:\n",
    "            break\n",
    "        if i == 0:\n",
    "            cur_span = example['offset_mapping'][i]\n",
    "            classes.append(get_class(c))\n",
    "        elif i > 0 and (c == pred[i-1] or (c-7) == pred[i-1]):\n",
    "            cur_span[1] = example['offset_mapping'][i][1]\n",
    "        else:\n",
    "            all_span.append(cur_span)\n",
    "            cur_span = example['offset_mapping'][i]\n",
    "            classes.append(get_class(c))\n",
    "    all_span.append(cur_span)\n",
    "    \n",
    "    if test: text = get_test_text(example_id)  # something wrong here\n",
    "    else: text = get_raw_text(example_id)\n",
    "    \n",
    "    # abra ka dabra se soli fanta ko pelo\n",
    "    \n",
    "    # map token ids to word (whitespace) token ids\n",
    "    predstrings = []\n",
    "    for span in all_span:\n",
    "        span_start = span[0]\n",
    "        span_end = span[1]\n",
    "        before = text[:span_start]\n",
    "        token_start = len(before.split())\n",
    "        if len(before) == 0: token_start = 0\n",
    "        elif before[-1] != ' ': token_start -= 1\n",
    "        num_tkns = len(text[span_start:span_end+1].split())\n",
    "        tkns = [str(x) for x in range(token_start, token_start+num_tkns)]\n",
    "        predstring = ' '.join(tkns)\n",
    "        predstrings.append(predstring)\n",
    "                    \n",
    "    rows = []\n",
    "    for c, span, predstring in zip(classes, all_span, predstrings):\n",
    "        e = {\n",
    "            'id': example_id,\n",
    "            'discourse_type': c,\n",
    "            'predictionstring': predstring,\n",
    "            'discourse_start': span[0],\n",
    "            'discourse_end': span[1],\n",
    "            'discourse': text[span[0]:span[1]+1]\n",
    "        }\n",
    "        rows.append(e)\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df['length'] = df['discourse'].apply(lambda t: len(t.split()))\n",
    "    \n",
    "    # short spans are likely to be false positives, we can choose a min number of tokens based on validation\n",
    "    df = df[df.length > min_tokens].reset_index(drop=True)\n",
    "    if viz: visualize(df, text)\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-23T23:03:17.634765Z",
     "iopub.execute_input": "2021-12-23T23:03:17.63535Z",
     "iopub.status.idle": "2021-12-23T23:03:17.655065Z",
     "shell.execute_reply.started": "2021-12-23T23:03:17.635228Z",
     "shell.execute_reply": "2021-12-23T23:03:17.653955Z"
    },
    "trusted": true
   },
   "execution_count": 88,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from spacy import displacy\n",
    "pred2span(preds[0], tokenized_val['test'][0], viz=True)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-23T23:03:17.658868Z",
     "iopub.execute_input": "2021-12-23T23:03:17.659221Z",
     "iopub.status.idle": "2021-12-23T23:03:17.712976Z",
     "shell.execute_reply.started": "2021-12-23T23:03:17.659184Z",
     "shell.execute_reply": "2021-12-23T23:03:17.711747Z"
    },
    "trusted": true
   },
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span class=\"tex2jax_ignore\"><h2 style=\"margin: 0\">7B5F5B33B566</h2>\n\n<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n<mark class=\"entity\" style=\"background: #8000ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    When people ask for advice\n\n, they sometimes talk to more than one person. Have you ever wounder why that is the case?, if\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Lead</span>\n</mark>\n \n<mark class=\"entity\" style=\"background: #2b7ff6; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    you are a person who does not take advice from another individual , then you could use this skill, taking advice from another person can\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Position</span>\n</mark>\n help you make better life choices, \n<mark class=\"entity\" style=\"background: #80ffb4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    it will make you understand things more clearly and faster,\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Claim</span>\n</mark>\n and learn from them. Multiple opinions really is a foundation to a job like a mayor of a city, it \n<mark class=\"entity\" style=\"background: #2adddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    is vital to take advice from the\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Evidence</span>\n</mark>\n community \n<mark class=\"entity\" style=\"background: #2adddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    in order to address problems and concerns. If it was just a city with no voice in the community then the city would fall into a bad place which no one wants to be in and the key advice is to receive it.\n\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Evidence</span>\n</mark>\n</br>In \n<mark class=\"entity\" style=\"background: #80ffb4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    the world we live in, we make a lot of important choices in life,\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Claim</span>\n</mark>\n some are big and some are \n<mark class=\"entity\" style=\"background: #80ffb4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    small, but they effect our future and success.\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Claim</span>\n</mark>\n Next, \n<mark class=\"entity\" style=\"background: #80ffb4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    advice from others can make you more wiser when you make your own choices,\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Claim</span>\n</mark>\n if\n<mark class=\"entity\" style=\"background: #2adddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    \n\nAbraham\n\nLincoln never saw how African Americans were treated for there skin color he would have never signed the documents for slavery to be band. if he never got advice he mostly likely would have never Andres the problems with having that toxic racism. If it wasnt for him, it would still be here today thanks to out 16th President, which boils down to good thinking and advice. At some point in our lives I know we got advice from someone we look up too,also what ever the advice they gave you, is an add on to bigger things, for example if a parent or guardian gives you some advice to never quit on things or problems that are hard and difficult for you, with just that you will Carey that for the rest of your life. Which eventually make you more wiser and resistant to challenges and in life. You will have a mindset that will help you be more successful and a hard worker. When you are at that point you will know what is right and wrong, from advice from your remodel, father, and mother. Multiple opinions is like trying different types of food from different chefs and if you just try it, you will see something you might like, if you never try something you will never see a different possibility taking advice is just like that. Only instead its intellects make the right choice to help you.\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Evidence</span>\n</mark>\n</br></br>In Conclusion, \n<mark class=\"entity\" style=\"background: d4dd80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    advice is there to help you, opinions are there to guide you to something that gives you smarts to making the right choices in the world we live in live, sure not all opinions hear might not be in your favor. But just hear them out and be the best you that you want to be shaped in, advice will make yo wiser and more aware of scenarios. \n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Concluding Statement</span>\n</mark>\n</div></span>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "             id        discourse_type  \\\n0  7B5F5B33B566                  Lead   \n1  7B5F5B33B566              Position   \n2  7B5F5B33B566                 Claim   \n3  7B5F5B33B566              Evidence   \n4  7B5F5B33B566              Evidence   \n5  7B5F5B33B566                 Claim   \n6  7B5F5B33B566                 Claim   \n7  7B5F5B33B566                 Claim   \n8  7B5F5B33B566              Evidence   \n9  7B5F5B33B566  Concluding Statement   \n\n                                    predictionstring  discourse_start  \\\n0  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...                0   \n1  24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 3...              123   \n2                      55 56 57 58 59 60 61 62 63 64              295   \n3                               85 86 87 88 89 90 91              453   \n4  93 94 95 96 97 98 99 100 101 102 103 104 105 1...              496   \n5  137 138 139 140 141 142 143 144 145 146 147 14...              703   \n6                    157 158 159 160 161 162 163 164              795   \n7  166 167 168 169 170 171 172 173 174 175 176 17...              848   \n8  180 181 182 183 184 185 186 187 188 189 190 19...              925   \n9  425 426 427 428 429 430 431 432 433 434 435 43...             2249   \n\n   discourse_end                                          discourse  length  \n0            122  When people ask for advice\\n\\n, they sometimes...      24  \n1            259  you are a person who does not take advice from...      25  \n2            354  it will make you understand things more clearl...      10  \n3            485                  is vital to take advice from the        7  \n4            699  in order to address problems and concerns. If ...      43  \n5            768  the world we live in, we make a lot of importa...      14  \n6            841    small, but they effect our future and success.        8  \n7            922  advice from others can make you more wiser whe...      14  \n8           2232  \\n\\nAbraham\\n\\nLincoln never saw how African A...     242  \n9           2587  advice is there to help you, opinions are ther...      68  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>discourse_type</th>\n      <th>predictionstring</th>\n      <th>discourse_start</th>\n      <th>discourse_end</th>\n      <th>discourse</th>\n      <th>length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7B5F5B33B566</td>\n      <td>Lead</td>\n      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n      <td>0</td>\n      <td>122</td>\n      <td>When people ask for advice\\n\\n, they sometimes...</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7B5F5B33B566</td>\n      <td>Position</td>\n      <td>24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 3...</td>\n      <td>123</td>\n      <td>259</td>\n      <td>you are a person who does not take advice from...</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7B5F5B33B566</td>\n      <td>Claim</td>\n      <td>55 56 57 58 59 60 61 62 63 64</td>\n      <td>295</td>\n      <td>354</td>\n      <td>it will make you understand things more clearl...</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7B5F5B33B566</td>\n      <td>Evidence</td>\n      <td>85 86 87 88 89 90 91</td>\n      <td>453</td>\n      <td>485</td>\n      <td>is vital to take advice from the</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7B5F5B33B566</td>\n      <td>Evidence</td>\n      <td>93 94 95 96 97 98 99 100 101 102 103 104 105 1...</td>\n      <td>496</td>\n      <td>699</td>\n      <td>in order to address problems and concerns. If ...</td>\n      <td>43</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>7B5F5B33B566</td>\n      <td>Claim</td>\n      <td>137 138 139 140 141 142 143 144 145 146 147 14...</td>\n      <td>703</td>\n      <td>768</td>\n      <td>the world we live in, we make a lot of importa...</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7B5F5B33B566</td>\n      <td>Claim</td>\n      <td>157 158 159 160 161 162 163 164</td>\n      <td>795</td>\n      <td>841</td>\n      <td>small, but they effect our future and success.</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7B5F5B33B566</td>\n      <td>Claim</td>\n      <td>166 167 168 169 170 171 172 173 174 175 176 17...</td>\n      <td>848</td>\n      <td>922</td>\n      <td>advice from others can make you more wiser whe...</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>7B5F5B33B566</td>\n      <td>Evidence</td>\n      <td>180 181 182 183 184 185 186 187 188 189 190 19...</td>\n      <td>925</td>\n      <td>2232</td>\n      <td>\\n\\nAbraham\\n\\nLincoln never saw how African A...</td>\n      <td>242</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>7B5F5B33B566</td>\n      <td>Concluding Statement</td>\n      <td>425 426 427 428 429 430 431 432 433 434 435 43...</td>\n      <td>2249</td>\n      <td>2587</td>\n      <td>advice is there to help you, opinions are ther...</td>\n      <td>68</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "pred2span(preds[1], tokenized_val['test'][1], viz=True)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-23T23:03:17.71609Z",
     "iopub.execute_input": "2021-12-23T23:03:17.716626Z",
     "iopub.status.idle": "2021-12-23T23:03:17.757272Z",
     "shell.execute_reply.started": "2021-12-23T23:03:17.716588Z",
     "shell.execute_reply": "2021-12-23T23:03:17.756227Z"
    },
    "trusted": true
   },
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span class=\"tex2jax_ignore\"><h2 style=\"margin: 0\">3CF52C3ED074</h2>\n\n<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n<mark class=\"entity\" style=\"background: #8000ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    All students do is waste their time and i'm tired of it. Students complain that school is like a prison but that is only because they don't realize the fun part of school.\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Lead</span>\n</mark>\n \n<mark class=\"entity\" style=\"background: #2b7ff6; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    I agree with the principal that all students should participate in at least one extracurricular activity. Students are too lazy instead of wasting time they should participate in after school activities.\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Position</span>\n</mark>\n For students it could benefit a lot, give kids good memories, and make school more fun.\n<mark class=\"entity\" style=\"background: #007f00; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    \n\nMy first reason is, It could benefit a lot.\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Other</span>\n</mark>\n \n<mark class=\"entity\" style=\"background: #2adddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Doing extracurricular activity can give an idea of what you want to do in the future. Sports is a very popular career choice for students but sports takes skills maybe sports could be your future. If your not very athletic thats ok many people enjoy debate club many politicians debate and if that is your skill maybe that can be your career. These after school activities can even help you learn about yourself. Make sure to participate in something you enjoy or try something you never done before. the best part about learning about yourself is finding your hidden talent in any type of activities.\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Evidence</span>\n</mark>\n\n<mark class=\"entity\" style=\"background: #007f00; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    \n\nMy next reasoning is, giving kids good memory's.\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Other</span>\n</mark>\n \n<mark class=\"entity\" style=\"background: #2adddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    In competitions there is always a reward, and good remember able thing is achieving that reward for your team and school. The highest achievement to accomplish is winning a tournament with your team. Even if you dont win at least you made it to the the finals. The most important part about extracurricular activity is having a fun time. No matter how popular you are you dont know everyone so get to know your teammates and make new friends. From my experience I played basketball and it was a really fun time but i'll never forget when i scored my first point. I promise you things are a lot more memorable when you do something exciting. Everyday you learn something new which can help you get better at what you activity you enjoy to do, and get to know your aquantince.\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Evidence</span>\n</mark>\n\n<mark class=\"entity\" style=\"background: #007f00; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    \n\nMy last reasoning is, it would make school way more fun.\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Other</span>\n</mark>\n \n<mark class=\"entity\" style=\"background: #2adddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Tell your friends and family what you did today. share with them your achievements, And what made your day. Make coming to more exciting. come to school prepared for after school activities. Now this might seem like too much pressure, but bring your school a trophy!\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Evidence</span>\n</mark>\n</br></br>In conclusion, \n<mark class=\"entity\" style=\"background: d4dd80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    i strongly agree with the principal decision that all students participate. Our school has a lot of activities that will interest all students. School goes by really fast so at least make the most of your years here. Because students are too lazy instead i believe all students should participate in after school activities. It would be beneficial for students, give students something to remember, and enjoy school more.\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Concluding Statement</span>\n</mark>\n</div></span>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "             id        discourse_type  \\\n0  3CF52C3ED074                  Lead   \n1  3CF52C3ED074              Position   \n2  3CF52C3ED074                 Other   \n3  3CF52C3ED074              Evidence   \n4  3CF52C3ED074                 Other   \n5  3CF52C3ED074              Evidence   \n6  3CF52C3ED074                 Other   \n7  3CF52C3ED074              Evidence   \n8  3CF52C3ED074  Concluding Statement   \n\n                                    predictionstring  discourse_start  \\\n0  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...                0   \n1  33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 4...              172   \n2                         79 80 81 82 83 84 85 86 87              463   \n3  89 90 91 92 93 94 95 96 97 98 99 100 101 102 1...              509   \n4                    193 194 195 196 197 198 199 200             1110   \n5  202 203 204 205 206 207 208 209 210 211 212 21...             1161   \n6        342 343 344 345 346 347 348 349 350 351 352             1935   \n7  354 355 356 357 358 359 360 361 362 363 364 36...             1994   \n8  402 403 404 405 406 407 408 409 410 411 412 41...             2277   \n\n   discourse_end                                          discourse  length  \n0            171  All students do is waste their time and i'm ti...      33  \n1            375  I agree with the principal that all students s...      31  \n2            508   \\n\\nMy first reason is, It could benefit a lot.        9  \n3           1110  Doing extracurricular activity can give an ide...     105  \n4           1160  \\n\\nMy next reasoning is, giving kids good mem...       8  \n5           1935  In competitions there is always a reward, and ...     141  \n6           1993  \\n\\nMy last reasoning is, it would make school...      11  \n7           2260  Tell your friends and family what you did toda...      46  \n8           2698  i strongly agree with the principal decision t...      69  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>discourse_type</th>\n      <th>predictionstring</th>\n      <th>discourse_start</th>\n      <th>discourse_end</th>\n      <th>discourse</th>\n      <th>length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3CF52C3ED074</td>\n      <td>Lead</td>\n      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n      <td>0</td>\n      <td>171</td>\n      <td>All students do is waste their time and i'm ti...</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3CF52C3ED074</td>\n      <td>Position</td>\n      <td>33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 4...</td>\n      <td>172</td>\n      <td>375</td>\n      <td>I agree with the principal that all students s...</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3CF52C3ED074</td>\n      <td>Other</td>\n      <td>79 80 81 82 83 84 85 86 87</td>\n      <td>463</td>\n      <td>508</td>\n      <td>\\n\\nMy first reason is, It could benefit a lot.</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3CF52C3ED074</td>\n      <td>Evidence</td>\n      <td>89 90 91 92 93 94 95 96 97 98 99 100 101 102 1...</td>\n      <td>509</td>\n      <td>1110</td>\n      <td>Doing extracurricular activity can give an ide...</td>\n      <td>105</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3CF52C3ED074</td>\n      <td>Other</td>\n      <td>193 194 195 196 197 198 199 200</td>\n      <td>1110</td>\n      <td>1160</td>\n      <td>\\n\\nMy next reasoning is, giving kids good mem...</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3CF52C3ED074</td>\n      <td>Evidence</td>\n      <td>202 203 204 205 206 207 208 209 210 211 212 21...</td>\n      <td>1161</td>\n      <td>1935</td>\n      <td>In competitions there is always a reward, and ...</td>\n      <td>141</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3CF52C3ED074</td>\n      <td>Other</td>\n      <td>342 343 344 345 346 347 348 349 350 351 352</td>\n      <td>1935</td>\n      <td>1993</td>\n      <td>\\n\\nMy last reasoning is, it would make school...</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3CF52C3ED074</td>\n      <td>Evidence</td>\n      <td>354 355 356 357 358 359 360 361 362 363 364 36...</td>\n      <td>1994</td>\n      <td>2260</td>\n      <td>Tell your friends and family what you did toda...</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3CF52C3ED074</td>\n      <td>Concluding Statement</td>\n      <td>402 403 404 405 406 407 408 409 410 411 412 41...</td>\n      <td>2277</td>\n      <td>2698</td>\n      <td>i strongly agree with the principal decision t...</td>\n      <td>69</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dfs = []\n",
    "for i in range(len(tokenized_val['test'])):\n",
    "    dfs.append(pred2span(preds[i], tokenized_val['test'][i]))\n",
    "\n",
    "pred_df = pd.concat(dfs, axis=0)\n",
    "pred_df['class'] = pred_df['discourse_type']\n",
    "pred_df"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-23T23:03:17.759337Z",
     "iopub.execute_input": "2021-12-23T23:03:17.760071Z",
     "iopub.status.idle": "2021-12-23T23:03:17.883329Z",
     "shell.execute_reply.started": "2021-12-23T23:03:17.760003Z",
     "shell.execute_reply": "2021-12-23T23:03:17.8822Z"
    },
    "trusted": true
   },
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "              id        discourse_type  \\\n0   7B5F5B33B566                  Lead   \n1   7B5F5B33B566              Position   \n2   7B5F5B33B566                 Claim   \n3   7B5F5B33B566              Evidence   \n4   7B5F5B33B566              Evidence   \n..           ...                   ...   \n4   B3E4B633261B                 Claim   \n5   B3E4B633261B              Evidence   \n6   B3E4B633261B          Counterclaim   \n7   B3E4B633261B              Rebuttal   \n8   B3E4B633261B  Concluding Statement   \n\n                                     predictionstring  discourse_start  \\\n0   0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...                0   \n1   24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 3...              123   \n2                       55 56 57 58 59 60 61 62 63 64              295   \n3                                85 86 87 88 89 90 91              453   \n4   93 94 95 96 97 98 99 100 101 102 103 104 105 1...              496   \n..                                                ...              ...   \n4   54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 6...              306   \n5   72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 8...              396   \n6                         126 127 128 129 130 131 132              689   \n7                     133 134 135 136 137 138 139 140              727   \n8   146 147 148 149 150 151 152 153 154 155 156 15...              795   \n\n    discourse_end                                          discourse  length  \\\n0             122  When people ask for advice\\n\\n, they sometimes...      24   \n1             259  you are a person who does not take advice from...      25   \n2             354  it will make you understand things more clearl...      10   \n3             485                  is vital to take advice from the        7   \n4             699  in order to address problems and concerns. If ...      43   \n..            ...                                                ...     ...   \n4             395  I also think if kid do community service it wi...      18   \n5             688  They will see all the people they helped all t...      54   \n6             726             Kids mite think your being unfair now        7   \n7             764             but they will thank you for it latter.       8   \n8             906  So i encourages you to require all students to...      21   \n\n                   class  \n0                   Lead  \n1               Position  \n2                  Claim  \n3               Evidence  \n4               Evidence  \n..                   ...  \n4                  Claim  \n5               Evidence  \n6           Counterclaim  \n7               Rebuttal  \n8   Concluding Statement  \n\n[15839 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>discourse_type</th>\n      <th>predictionstring</th>\n      <th>discourse_start</th>\n      <th>discourse_end</th>\n      <th>discourse</th>\n      <th>length</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7B5F5B33B566</td>\n      <td>Lead</td>\n      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n      <td>0</td>\n      <td>122</td>\n      <td>When people ask for advice\\n\\n, they sometimes...</td>\n      <td>24</td>\n      <td>Lead</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7B5F5B33B566</td>\n      <td>Position</td>\n      <td>24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 3...</td>\n      <td>123</td>\n      <td>259</td>\n      <td>you are a person who does not take advice from...</td>\n      <td>25</td>\n      <td>Position</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7B5F5B33B566</td>\n      <td>Claim</td>\n      <td>55 56 57 58 59 60 61 62 63 64</td>\n      <td>295</td>\n      <td>354</td>\n      <td>it will make you understand things more clearl...</td>\n      <td>10</td>\n      <td>Claim</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7B5F5B33B566</td>\n      <td>Evidence</td>\n      <td>85 86 87 88 89 90 91</td>\n      <td>453</td>\n      <td>485</td>\n      <td>is vital to take advice from the</td>\n      <td>7</td>\n      <td>Evidence</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7B5F5B33B566</td>\n      <td>Evidence</td>\n      <td>93 94 95 96 97 98 99 100 101 102 103 104 105 1...</td>\n      <td>496</td>\n      <td>699</td>\n      <td>in order to address problems and concerns. If ...</td>\n      <td>43</td>\n      <td>Evidence</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>B3E4B633261B</td>\n      <td>Claim</td>\n      <td>54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 6...</td>\n      <td>306</td>\n      <td>395</td>\n      <td>I also think if kid do community service it wi...</td>\n      <td>18</td>\n      <td>Claim</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>B3E4B633261B</td>\n      <td>Evidence</td>\n      <td>72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 8...</td>\n      <td>396</td>\n      <td>688</td>\n      <td>They will see all the people they helped all t...</td>\n      <td>54</td>\n      <td>Evidence</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>B3E4B633261B</td>\n      <td>Counterclaim</td>\n      <td>126 127 128 129 130 131 132</td>\n      <td>689</td>\n      <td>726</td>\n      <td>Kids mite think your being unfair now</td>\n      <td>7</td>\n      <td>Counterclaim</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>B3E4B633261B</td>\n      <td>Rebuttal</td>\n      <td>133 134 135 136 137 138 139 140</td>\n      <td>727</td>\n      <td>764</td>\n      <td>but they will thank you for it latter.</td>\n      <td>8</td>\n      <td>Rebuttal</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>B3E4B633261B</td>\n      <td>Concluding Statement</td>\n      <td>146 147 148 149 150 151 152 153 154 155 156 15...</td>\n      <td>795</td>\n      <td>906</td>\n      <td>So i encourages you to require all students to...</td>\n      <td>21</td>\n      <td>Concluding Statement</td>\n    </tr>\n  </tbody>\n</table>\n<p>15839 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# source: https://www.kaggle.com/robikscube/student-writing-competition-twitch#Competition-Metric-Code\n",
    "\n",
    "def calc_overlap(row):\n",
    "    \"\"\"\n",
    "    Calculates the overlap between prediction and\n",
    "    ground truth and overlap percentages used for determining\n",
    "    true positives.\n",
    "    \"\"\"\n",
    "    set_pred = set(row.predictionstring_pred.split(\" \"))\n",
    "    set_gt = set(row.predictionstring_gt.split(\" \"))\n",
    "    # Length of each and intersection\n",
    "    len_gt = len(set_gt)\n",
    "    len_pred = len(set_pred)\n",
    "    inter = len(set_gt.intersection(set_pred))\n",
    "    overlap_1 = inter / len_gt\n",
    "    overlap_2 = inter / len_pred\n",
    "    return [overlap_1, overlap_2]\n",
    "\n",
    "\n",
    "def score_feedback_comp_micro(pred_df, gt_df):\n",
    "    \"\"\"\n",
    "    A function that scores for the kaggle\n",
    "        Student Writing Competition\n",
    "\n",
    "    Uses the steps in the evaluation page here:\n",
    "        https://www.kaggle.com/c/feedback-prize-2021/overview/evaluation\n",
    "    \"\"\"\n",
    "    gt_df = (\n",
    "        gt_df[[\"id\", \"discourse_type\", \"predictionstring\"]]\n",
    "        .reset_index(drop=True)\n",
    "        .copy()\n",
    "    )\n",
    "    pred_df = pred_df[[\"id\", \"class\", \"predictionstring\"]].reset_index(drop=True).copy()\n",
    "    pred_df[\"pred_id\"] = pred_df.index\n",
    "    gt_df[\"gt_id\"] = gt_df.index\n",
    "    # Step 1. all ground truths and predictions for a given class are compared.\n",
    "    joined = pred_df.merge(\n",
    "        gt_df,\n",
    "        left_on=[\"id\", \"class\"],\n",
    "        right_on=[\"id\", \"discourse_type\"],\n",
    "        how=\"outer\",\n",
    "        suffixes=(\"_pred\", \"_gt\"),\n",
    "    )\n",
    "    joined[\"predictionstring_gt\"] = joined[\"predictionstring_gt\"].fillna(\" \")\n",
    "    joined[\"predictionstring_pred\"] = joined[\"predictionstring_pred\"].fillna(\" \")\n",
    "\n",
    "    joined[\"overlaps\"] = joined.apply(calc_overlap, axis=1)\n",
    "\n",
    "    # 2. If the overlap between the ground truth and prediction is >= 0.5,\n",
    "    # and the overlap between the prediction and the ground truth >= 0.5,\n",
    "    # the prediction is a match and considered a true positive.\n",
    "    # If multiple matches exist, the match with the highest pair of overlaps is taken.\n",
    "    joined[\"overlap1\"] = joined[\"overlaps\"].apply(lambda x: eval(str(x))[0])\n",
    "    joined[\"overlap2\"] = joined[\"overlaps\"].apply(lambda x: eval(str(x))[1])\n",
    "\n",
    "    joined[\"potential_TP\"] = (joined[\"overlap1\"] >= 0.5) & (joined[\"overlap2\"] >= 0.5)\n",
    "    joined[\"max_overlap\"] = joined[[\"overlap1\", \"overlap2\"]].max(axis=1)\n",
    "    tp_pred_ids = (\n",
    "        joined.query(\"potential_TP\")\n",
    "        .sort_values(\"max_overlap\", ascending=False)\n",
    "        .groupby([\"id\", \"predictionstring_gt\"])\n",
    "        .first()[\"pred_id\"]\n",
    "        .values\n",
    "    )\n",
    "\n",
    "    # 3. Any unmatched ground truths are false negatives\n",
    "    # and any unmatched predictions are false positives.\n",
    "    fp_pred_ids = [p for p in joined[\"pred_id\"].unique() if p not in tp_pred_ids]\n",
    "\n",
    "    matched_gt_ids = joined.query(\"potential_TP\")[\"gt_id\"].unique()\n",
    "    unmatched_gt_ids = [c for c in joined[\"gt_id\"].unique() if c not in matched_gt_ids]\n",
    "\n",
    "    # Get numbers of each type\n",
    "    TP = len(tp_pred_ids)\n",
    "    FP = len(fp_pred_ids)\n",
    "    FN = len(unmatched_gt_ids)\n",
    "    # calc microf1\n",
    "    my_f1_score = TP / (TP + 0.5 * (FP + FN))\n",
    "    return my_f1_score\n",
    "\n",
    "\n",
    "def score_feedback_comp(pred_df, gt_df, return_class_scores=False):\n",
    "    class_scores = {}\n",
    "    pred_df = pred_df[[\"id\", \"class\", \"predictionstring\"]].reset_index(drop=True).copy()\n",
    "    for discourse_type, gt_subset in gt_df.groupby(\"discourse_type\"):\n",
    "        pred_subset = (\n",
    "            pred_df.loc[pred_df[\"class\"] == discourse_type]\n",
    "            .reset_index(drop=True)\n",
    "            .copy()\n",
    "        )\n",
    "        class_score = score_feedback_comp_micro(pred_subset, gt_subset)\n",
    "        class_scores[discourse_type] = class_score\n",
    "    f1 = np.mean([v for v in class_scores.values()])\n",
    "    if return_class_scores:\n",
    "        return f1, class_scores\n",
    "    return f1"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-23T23:03:17.885121Z",
     "iopub.execute_input": "2021-12-23T23:03:17.885735Z",
     "iopub.status.idle": "2021-12-23T23:03:17.908285Z",
     "shell.execute_reply.started": "2021-12-23T23:03:17.88567Z",
     "shell.execute_reply": "2021-12-23T23:03:17.907198Z"
    },
    "trusted": true
   },
   "execution_count": 94,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CV Score"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "score_feedback_comp(pred_df, gt_df, return_class_scores=True)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-23T23:03:17.910018Z",
     "iopub.execute_input": "2021-12-23T23:03:17.910701Z",
     "iopub.status.idle": "2021-12-23T23:03:18.110011Z",
     "shell.execute_reply.started": "2021-12-23T23:03:17.910652Z",
     "shell.execute_reply": "2021-12-23T23:03:18.108723Z"
    },
    "trusted": true
   },
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.6228175495455742,\n {'Claim': 0.5530627152248774,\n  'Concluding Statement': 0.8128161888701517,\n  'Counterclaim': 0.4755989352262644,\n  'Evidence': 0.6921063229963753,\n  'Lead': 0.7849624060150376,\n  'Position': 0.6573612495845796,\n  'Rebuttal': 0.3838150289017341})"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ]
}